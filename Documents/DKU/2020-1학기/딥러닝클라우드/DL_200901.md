# 목차

[200901](#200901)
[200911](#200911)
[200915](#200915)
[200922](#200922)
[200929](#200929)

# 200901

## 수업 개요

### 교과목 목표

- 딥러닝의 기본 개념
- 딥러닝을 현실 문제에 적용할 수 있는 방법론 학습
- 카페(Caffe), 텐서플로우(Tensorflow) 등 주요 딥러닝 프레임워크
- 클라우드 환경에서의 데이터 처리

### 기대되는 학습성과

- 파이썬의 딥러닝 관련 라이브러리 활용 가능
- 머신러닝의 개념 이해(딥러닝보다 넓은 차원의 개념)
- 클라우드 컴퓨팅의 종류와 동작 방식
- Keras(프레임워크)를 이용해 딥러닝 문제를 해결

1주차

## Deep Learning

인공지능: 기계 등이 인간과 같은 지능, 판단 할 수 있게 하는 -> 이것의 연장선상에 딥러닝이 있음

![image](https://user-images.githubusercontent.com/33214449/92207133-b28f7180-eec3-11ea-9a91-68d3b779d290.png)

출처: https://www.datacatchup.com/wp-content/uploads/2019/05/image.png

## Cloud

온프레미스
IaaS
PaaS
SaaS

![image](https://user-images.githubusercontent.com/33214449/92207542-5aa53a80-eec4-11ea-97d9-d8a2d433cffd.png)

## 실습 환경

PC - Anaconda 를 이용해 Python 사용할 것
Cloud - GoogleColab

# 200911

2주차

## 주의

문법 위주의 설명. 강의에서 코드실행은 하지 않으니 코드를 실행해볼것

파이썬은 인터프리터 언어(컴파일 과정이 없음. 라인바이라인 실행. 명령어를 치면 바로 결과를 확인할 수 있는)

텐서플로같은 잘 알려진 딥러닝 라이브러리를(API를) 파이썬이 지원함
딥러닝, 머신러닝할 때 데이터를 다루는 것이 중요한데 파이썬은 numpy같은 라이브러리를 제공하고 다루기가 용이

5페이지

제곱은 \*\*

7페이지

파이썬은 명시적인 변수 선언이 없다

초기화를해야 변수를 쓸 수 있음

변수의 값을 확인하는 방법

- 1. 명시적으로 print
- 2. 변수명만 입력해도 변수의 값이 출력됨

2번째 강의 ~

8페이지

따로 char 없음
bool형은 대소문자 지켜서 쓰기 (True, False)

12페이지

`{0}` 여기에 어떤 값이 출력되는데 뒤에서 보면 x가 넣어지는 것

13페이지

`{0}` `{1}` `{2}` 안에 숫자는 인덱스를 나타내는 것

14페이지

뒤로가면 리스트보다 편한 거 쓰지만 알아야되긴하니까 함

17페이지

range()
뒤는 +1임 기억
range(5,10) 5~9까지 만듬
range로 만든 요소값은 변경 불가

18페이지

range 형을 list로 바꾸면 요소를 수정 가능

시작 숫자 생략하면 0부터 시작되는 수열
range(10) : 0~9

19페이지

tuple -> 잘 안씀 그냥 넘ㅇ어가~

a = (1) 이렇게 쓰면 int로 인식

3번째 강의~

22페이지

같은 깊이로 들여쓰기 할 것!

23페이지

and or

24페이지

enumerate 열거형
순서는 i, 실제 값이 들어오는건 n

25페이지

numpy 넘파이를이용한 배열
파이썬 라이브러리-> 모듈이라고 부름
리스트도 있지만... 넘파이는 배열을 쉽게 다룰 수 있게 해줌
리스트보다 처리 속도가 50배정도 빠르다
n차원의 배열을 선언할 수 있다.(넘파이에서 배열객체를 ndarray라고 함)

26페이지

넘파이에서 1차원 배열은 vector라고함

28페이지

numpy.arange

29페이지

벡터연산(리스트와 차이)
배열과 배열의 덧셈이 됨(c언어라생각하면 for문 돌려서 해야됐을것)
연산하려면 차원이 같아야됨

30페이지

2차원->array

array 의 크기
2행 3열 의미
dtype 데이터 타입!

4번째 강의~

31페이지

2행 10열의 배열이 생성됨

32페이지

rand 0에서 1사이 랜덤한 거 나옴

(seed 같으면 랜덤하긴해도 내가하든 남이하든 같은 랜덤값
seed 다르면 매번 다른 결과)

33페이지

reshape 원소의 총 개수는 같아야 사용 가능
벡터를 차원으로 바꿀 수도 있음, 2차원도 옆으로 늘려 벡터로 만들 수도 있고

36페이지

배열값 각각에 대해서 수학 연산 할 수 있음

37페이지

행렬곱셈 의 의미(딥러닝에서 많이 쓴대)
v.dot(w)

w.dot(v) 와 결과 다름

38페이지
잘라내 여러개 추출할 수 있다

[:5] 처음부터 5인덱스 바로 전까지 자름
[2:5] 인덱스 2 부터 인덱스 5전까지. 즉 인덱스 2,3,4

[n:] n부터 끝까지 다

39페이지

[:,1] 행은 처음부터끝까지, 열은 1행만

41페이지
함수에 대해서 알고싶을 때

43페이지

파이썬에서는 리턴값을 여러개 줄 수 있음

(파이썬은 블록단위로 다른문장 먼저 실행하면 그 데이터 갖다쓰는 코드 그다음에 실행해도 실행되네)

44페이지
배열의 값을 파일에 저장해놓을 수 있음(중요한 결과값이라면 이런 과정 필요!)

45페이지
많이쓰진 않음

# 200915

3주차

chap03_1,2,3 부분 피피티 다시 정독할 것

## 수업 개요

- AI scopes
- Machine learning
- Machine learning areas
- Development process of learning model
- Sciket-learn

## DC_chap03_1_compact

3페이지
머신러닝은 독립적인 분야라기보다는 많은 것과 관련되어있다(인공지능에 속하고, 패턴 인식, 통계학, 시각화 등과 관련 있음)

4페이지
머신러닝 이나 데이터마이닝 겹치는 부분 있어. 대량의 데이터가 관여된다.
데이터마이닝: 정보를 뽑아내는
머신러닝: 데이터를 토대로 예측하는

5페이지
인공지능: 컴퓨터가 사람처럼 행동하게끔 할 수 있게하는 기술
머신러닝: 통계적인 방법과 데이터를 활용해 문제를 더 잘 해결하게끔하는 인공지능 기술
딥러닝: 뉴럴 네트워크

6페이지
머신러닝이 뭘까? 머신이 기계일까 학습한다는 것은 무엇일까?
구체적으로 뭘 한다는 것일까?

7페이지

머신러닝 (실제적인 의미): 과거의 경험을 미래의 결정(예측)에 활용하는 소프트웨어를 디자인하고 연구하는 분야

=>과거를 공부해 미래를 예측하는 기술
과거 데이터로부터 숨겨진 규칙을 찾아내 일반화-> 이를 미래 예측에 활용

과거의 경험 자체를 잘 이해하는 것 유용한 정보를 뽑아내려고 하는 것=> 데이터 마이닝
여기서 규칙을 찾아 미래 예측에 활용하려 하는 것은 머신러닝

전통적 SW
규칙을 인간이 알아내어 알고리즘 형태로 SW 안에 구현한 것(이게 규칙이겠지~)
누가 알고리즘을 잘 만드느냐가 SW엔지니어의 능력이었음
(알고리즘은 규칙을 찾아가는 과정을 다 서술한 것)

머신러닝
규칙을 알아내는 방법은 인간이 제시(방법론만을 제시)
머신이 규칙을 찾는다. (전통적 SW 와의 차이)
머신이 과거데이터로부터 규칙을 알아내는 과정이 '학습'(머신입장에선 학습, 인간입장에선 머신을 '훈련'시키는 것)

인공지능 > 머신러닝 > 딥러닝 (포함관계)

머신러닝: 과거의 축적된 데이터를 '학습'하여 미래를 예측하는 기술

8페이지

머신 러닝은 기본적으로 데이터가 있어야한다.

예측모델 -> 규칙을 의미 (어떨 때 주가가 이렇더라)
이제 데이터가 있고 내일 주가를 모르면 그 데이터를 모델에 넣어 주가 예측할 수 있는 것

9페이지

머신 러닝에서 '머신' -> SW, 프로그램

10페이지

머신러닝이 사용하는 학습 자료는? 데이터
엑셀 형태의 데이터. sns에서 오가는 데이터들, 이미지, 음성파일 등

11페이지

'러닝'은 무엇인가?

설명변수:아까 본 주식에 영향을 미치는 요인들(여러개)
반응변수:요인들에 의해 결정되는 주가(하나)

잘 정돈된 데이터인 데이터셋(설명변수, 반응변수)를
학습방법에 집어넣으면... 러닝이 됨(머신입장)
학습의 아웃풋은 예측 모델이라함

12페이지
러닝의 사례들

13페이지
이런 학습 알고리즘을 잘 사용할 줄 알면됨

15페이지
관건은 얼마나 정확한 모델을 만드느냐가 관건

## DC_chap03_2_compact

17페이지

우리수업에선 지도학습 주로 학습(비지도학습은 조금, 강화학습은 다루지 않음)

- 지도학습 (가이드하는 학습방법)
  문제, 답을 같이 줘서(설명변수, 반응변수를 같이 주고) 학습시키는 것이 지도학습

  - 회귀(답의 형태가 수치형. 값이 있고 크기 비교가 가능한)
  - 분류(답이 범주형.)->수업에서 제일 많이 다룰 것

정답의 형태에 따라 회귀, 분류로 나눠짐
맞추고자하는 답의 형태가 수치형이면 회귀
(분류문제 가장 많이 다룸)

- 비지도학습
  문제만 주고 답은 안줌

18페이지

세모를 모델에 넣으면 -인지 +인지 알려주는 (분류의 예)

처음엔 그룹이 뭔지도 모름
그룹이 어떻게 구성되는지 찾아봐라(군집화)

위 둘의 차이는
분류는 그룹 정보가 이미 주어진다.
군집화는 그룹 정보 없이 스스로 그룹 정보를 만들어내야함

19페이지

오존이 120 일때 기온은 얼마일까? 예측 가능
예측해야될 대상이 클래스나 범주가 아니라 숫자라면
regression

20페이지
처음에는 비실비실한데 나중에는 잘 치게 됨

## DC_chap03_3_compact

요 영상 중요하대

22페이지

개발자 입장에서 어떻게 모델을 개발하는지 과정 도식화한 것

학습에 사용할 training data
학습에 사용하지 않는 test data 로 나눔

만든 모델의 성능을 평가하는 것이 굉장히 중요
(평가를 어떻게 하지? 어차피 미래를 예측하는 건데?)

test data가 미래 데이터로 보고
학습에 안쓴 test data를 미래 데이터로 보고 이걸 가지고 예측해 예측 결과를 도출.
그리고 test data는 이미 결과를(Y) 가지고 있으니까 예측한거랑 이거랑 비교해서 모델을 평가

validatoin data 는 현재 이루어지고 있는 학습 과정이 잘 가고 있는지를 평가하기 위한 데이터이다.(부족한 부분 보충) 어떤 모델은 이게 있고 어떤 모델은 없는 알고리즘도 있음

---

머신러닝의 아웃풋은 '학습 모델'

22페이지 표 자주 나올 것

test data(일부 남겨놓은)를 미래 데이터로 보고
그 학습과 학습시킨 모델과 비교

비교해 많이 일치할 수록 모델이 정확도가 높다 이렇게 판단할 수 있음

---

24페이지

각각 모델 의 결과와 이미 있는 결과(Y)를 이용해 accuracy 도출 가능

왜?
training data를 통해 학습했기 때문에 training accuracy 정확도가 높음

## DC_chap03_4_compact

파이썬에서 머신러닝을 위해 사용되는 두가지 라이브러리 소개할 것

25페이지

1. sciket-learn (라이브러리1)

여기 있는 함수 많이 배울 것

26페이지

2. pandas (라이브러리2)

학습에 쓸 데이터가 보통 파일에 저장되어있는데 그걸 불러와서
데이터 프레임(넘파이에 있는 것 처럼 2차원 배열같은)에 저장할 수 있음
그리고 그 데이터프레임을 가공 가능(어디부터 어디까지 잘라서 쓰고 등등)

27페이지

꽃받침의 길이와 너비, 꽃잎의 길이와 너비(x) 주고 이게 품종(y, 결과)이 뭘까? 분류할 수 있을것(이 학습데이터를 바탕으로)

28페이지

iris 가 데이터프레임을 담고있게됨

with display.max... 생략된 데이터 없이 행, 컬럼 다 보일 수 있게함

head() 데이터를 앞부터 몇개만 보고싶을 때
인수로 숫자를 주면 몇개도 설정가능

tail()은 그 반대

iris.shape 행과 열만 알고싶을 경우

columns 컬럼의 이름을 보고싶은경우(컬럼은 실데이터는 아님)

columns[:4] 앞에서 시작해 4번째까지(0,1,2,3)

iris['컬럼이름'] 해당하는 컬럼 데이터만 가져옴
iris[['컬럼이름', '컬럼이름']]
이렇게 잘라내고 또다른 변수에 저장해 데이터프레임처럼 쓸 수 있음

iloc도 기준이 행은 인덱스고 열은 0부터시작하는 값인듯
iloc 인덱스를 이용해 자르는 방법
iloc[90,4] 인덱스 90에 해당하는 행과 4에 해당하는 열 -> 열도 0부터시작하니 실제론 5번째 열에 있는 데이터가 나올 것

iloc[10:50, 0:4] 10~50 행, 0~4열에 해당하는 데이터 가져오는
iloc[10:50, :] 10-50 행, 열은 모두 라는 의미

조건을 주고 자르는 경우
논리식은 데이터마다 t, f 판별한 정보 가지고 있음
iris[setosa] 품종이 setosa 인 것만 보여줄 것
& -> and의미 두 조건을 만족하는 것만 골라오는 것

30페이지

어떤 모듈 설치되어있는지 확인 가능한 명령어

# 200922

## 수업 개요

1. Simple linear regression 단순 선형 회귀
2. Multiple linear regression 다중 선형 회귀
3. Logistic regression

회귀문제 이면서 분류도 풀 수 있음 오늘 다룰 것

## 수업 내용

### DC_chao04_1_compact

1. Simple linear regression

4페이지

독립, 종속 변수의 두 관계가 선형관계인지 파악하고(하나 증가하면 다른 하나도 증가하거나 하나 감소하면 다른 하나도 감소하거나) 이를 예측에 활용하는

모델 = (구체적으로 말하면)학습 모델

머신이 W,b 같은 상수를 알아내게 하는게 목표임

6페이지

산점도

오른쪽 두개는 선형관계가 아닌 경우임

오른쪽위는 이차식이 될 것

왼쪽것에 단순선형회귀를 적용할 수 있다.

7페이지

(a) 가 더 좋아보이는데
이걸 객관적으로 평가할 수 있는 척도가 필요함

8페이지

오차들의 합계가 가장 적어야함

예측값-실제값이 마이너스인 경우도 있고 플러스인경우도 있음
그래서 각각을 제곱해서 더해줌.

12페이지

regression 하려면 넘파이 배열로 담아줘야함.
그리고 reshape으로 2차원 배열이 되도록해줘야해(여기서는)

13페이지
test_size=0.2
test data를 20프로로 하겠다는것(그럼 training data는 80프로가 되겠지)

random_state 랜덤 시드값 (실행시마다 랜덤으로 정하는 것 고정시키려고)여기선 train test 나누는 것을 랜덤으로 햇을때 그걸 이후에도 사용하기 위해서

14페이지

모델만들 때 방법 지정

fit=learning 학습하여 W,b얻을 수 있음

predict로 예측
pred_y랑 test_y랑 비교해서 정확한지 보면되겠지

15페이지

값 하나로 예측하고 싶을 때(곽갈호 2개인 것에 유의-predict가 2차원 배열을 받아들이기 때문에)

16페이지

실제는 아래 코드처럼 써야함

W,b 출력할 수 있음(학습이 끝난 모델안에 들어있는 것)

17페이지

모델 평가 1

mean squared error
실제값-정답값 의 제곱을 더해 평균낸 것(오차의 제곱의 합 평균)
이 값이 작을 수록 정확한 모델

0이면 예측이 정확하다는 것인데 이는 이상적인 값

근데 이 오차가 얼마나 작은것인지를 추측하기가 힘듦

18페이지

모델 평가 2

r2 score
1에 가까울 수록 좋은 모델인 걸 알 수 있기 때문에 모델 평가 1보다 보기 쉬움

19페이지

scatter 산점도 그리는 것
plot 라인 그리는 것

### DC_chao04_2_compact

2. Multiple linear regression
   중 선형 회귀
   다중 선형 회귀

20페이지

독립변수가 2개 이상인 경우(단일 선형 회귀와의 차이점)

intercept 편차

22페이지

c income 연봉을 예측하고싶음(선형)

교육년수, 여성비율, 직업에 대한 평판 쓸 것

26페이지

단순 선형 회귀와 코드 방식은 비슷

27페이지

독립변수가 3개라 coefficient계수도 3개가 나옴

28페이지
각괄호 2개 해도 되고
이렇게 reshape 써도 되고

### DC_chao04_3_compact

3. Logisic regression

분류 문제를 회귀 방법으로 풀려고 하는 것

30페이지

이것도 어차피 회귀라 품종도 숫자로 나타내야함

33페이지

전체 정답중에 정답을 맞춘 개수

분류가 logistic regression 보다 성능 좋지만 배우는 건 필요하니까!

# 200929

5주차

## DC_chap05_1_compact

1. remind: clustering, classification

3페이지

clustering(군집화)
비슷한 데이터들끼리 묶는 작업
(알아서 묶음)비지도적 학습
거리가 가까운 것들끼리 묶음-> 거리계산이 중요

4페이지

classification 분류
이미 범주를 알고 있음
남자 / 여자 나눌 때 어떤 정보가 남자인지 여자인지 구별
예측, 진료에 많이 쓰임
이 수업에서 많이 배울 것
지도적 학습(이미 범주데이터-정답이 주어지기 때문에)

6페이지

이렇게 그룹을 만들어 해석.
속도는 느리고, 무게는 무겁고...~~~ 아마 화물차일것

그룹지어짐>특성 존재

7페이지

환자와 정상인
아래 데이터를 보고 어떤 범주(환자or정상)에 속하는지 구하는

8페이지
분류는 이미지를 가지고도 할 수 있다.

사진속 장소 이름 뭔지 모르겠을 때 > 비슷한거 찾음

9페이지

분류가 두개일 때 -> binary

multiple
알파벳은 스물 몇개겠지(클래스가)

binary vs multiple 뭐가 쉬울까?
binary가 쉽겠지. 찍어도 50프로니
모델의 정확도가 비교적 높다는 뜻

## DC_chap05_2_compact

2. k-means clustering

11페이지

서로 다른 주파수대역에서 음파를 측정
금이가고 안간 타일을 구분하기 위해

군집화해서 금간것끼리 금안간것끼리 묶여야 사용 가능

12페이지

로그값을 취해 값을 좀 줄여줌(logarithms)

k=>클러스터의 개수
금이간 타일 정상 타일 예는 k=2이겠지

14페이지
가상의 점 k개 찍기
-> 각 클러스터의 중심점이 될것
이 점들과 나머지 원래 데이터들의 각각 거리 측정
(각각의 점이 가상의 점들 중 뭐랑 가까운지 계산하고 그룹화)
더 가까운 점을 포함시켜 중심점 계산(x좌표 다 더하고-가상 점 포함- 점 개수만큼 나눔.)

![image](https://user-images.githubusercontent.com/33214449/95008868-68cbaf80-0658-11eb-80a2-c8945025af8c.png)

15페이지

14페이지 반복

22페이지
labels
각 데이터의 클러스터 뭔지

붙여서 잘 보여주려고 한것
hstack 수평으로 쌓기

reshape(-1,1) 행은 너가 알아서 맞춰 라는 뜻
21페이지에 있는 데이터랑 붙이려면 reshape 해줘야해(세로로 세우는 작업)

cluster_centers 중심점
첫번째께 0번 클러스터, 두번째께 1번 클러스터

[0,0]은 어떤 클러스터일까 이렇게 추측해보는 것 (predict)

## DC_chap05_3_compact

3. KNN classifier

25페이지

별 데이터는 동그라미인지 세모인지 모른다고 할 때

knn
모르는 데이터에 가까운애들을 줄임(7-nn)
그중 많은 클래스를따른다.(여기선 동그라미)

26페이지

클래스수가 동수일때는 어떻게하나?
K를 몇으로 해야되나 이슈가 발생

27페이지

거리계산은 k-means에서 봤던 식과 같음

28페이지

루트 n보다 작게 k를 잡아라

29페이지

색깔있는 숫자가 정답

아래 색깔 그려진건 예측값

k숫자가 커질 수록 예측값 정확도가 점점 떨어짐을 볼 수 있음

k 1,3,5 다 해보고 제일 정확한걸 고름
하이퍼파라미터: 모델을 만들 때 모델의 정확도(성능)를 결정하는 몇가지의 변수들을 의미(knn에서는 하이퍼 파라미터가 k 하나겠지)

30페이지

데이터 분포가 어떻든지 분석 가능(통계적 가정 불필요)

데이터 커질 수록
새로운 데이터를 데이터들과 거리를 계산해야되서
데이터를 메모리에 다갖고있어야됨

계산도 많이해야되니까 처리시간 증가

32페이지

k값을 3으로 줌

fit함수 -> 학습하는 것

classfication 분류에서 모델 성능 평가시 많이 쓰는 것 accuracy
(전체 테스트 데이터 갯수중에 정답맞힌 갯수)

34페이지

ex예로 거리를 계산해보면
실제로 차이가 많이나는 건 시력인데(1.0 과 0.1)
거리 값에 영향을 크게 미치는 건 키 값임을 알 수 있음
둘의 스케일이 다름

키도 0~1로 시력도 0~1로 동일한 영향력을 갖도록 스케일링을 해줘야함

kmeans knn 하려면 스케일링 해야함

## DC_chap05_4_compact

4. perfomance metric

37페이지

성능 평가!

binary classification의 경우 이런 성능평가 척도 가지고 있다.(why 모델이 어디 적용되느냐에따라 다양한 것이 사용됨)

38페이지

T : 잘 맞춘것

FP,FN은 오류
FN이 더 심각하지(코로나라고 생각하면)

accuracy는 경우중에 정답인 것만

39페이지

민감도
ex) 양성인 사람중에 양성이라고 예측한 비율

특이도
ex) 음성인 사람중에 음성이라고 예측한 비율

의료환경에서는 무엇이 중요할까? 민감도가 중요할 것.(환자인데 음성이라고 진단한 경우가 높으면 큰일이니)

40페이지

정밀도

양성이라고 예측한 사람들 중에 진짜 양성인 사람

41페이지

f1 score
민감도와 특이도의 불균형 측정

민감도가 100퍼센트인데(1) 특이도가 0이면 f1 score는 0

불균형한 경우 척도값이 낮게 나오는게 f1 score

42페이지
class가 3개이면 성능 측정 어떻게 하나?
(multiple class model)

클래스별로 민감도 특이도를 계산할 수 있으나 잘 쓰지 않음

43페이지

classification에서 쓰는 척도들

모델을 만드는 것도 중요하지만 성능을 측정하는 것도 중요

45페이지
인자 줄 때 정답이 앞에 예측이 뒤에 와야됨!

46페이지
3x3행렬보면...
test_y가 정답임

정답은 0 인데 예측도 0으로한건 2개라는 뜻
대각선이 제대로 맞춘 것들을 나타냄

## DC_chap05_5_compact

5. k-fold cross validation

validation이니까 평가해서 알아보는 것임

이 결과를 믿어야할까?라는 것
training , test 데이터를 어떻게 나누느냐에 따라 정확도가 엄청 달라질 수도 있음

-> 해결하려면
나누는 걸 여러번 해서 평균을 할 수도 있음
아니면
k-fold cross validation사용

50페이지

k=4면 전체를 4등분하는 것

ex1에서 진한걸 test, 나머지 training
ex2도
ex3도
ex4도

각각의 accuracy를 평균하고
이걸 그 모델의 accuracy로 보자는 것

k=10이면
10번 나누겠지
10번 모델을 만들거고

51페이지

랜덤하게 나누니까 random_state 줘야함(이후에도 같은 결과 얻으려면)
shuffle 데이터를 마구 섞고 등분할거냐 물어보는 것

knn사용한 것

accuracy 저장할 크기 5인 배열 선언

53페이지

np.mean 평균

54페이지

좀더 단순한 방법

fold쓰지 않고 cross \_val_score 사용

단지 accuracy만 구하기 때문에 사이에 코드를 넣으려면 전 페이지처럼 자세하게 하는게 좋을 수도

55페이지

k-fold
원하는 모델을 도출하지는 않음(모델 여러개 나오잖아)
정확도를 추정하는 용도

knn쓴다했을 때
k정해야함. 여러번해서 좋은거 써야함
이때 k-fold 써서 k가 몇일때 정확도 몇이고 이런걸 구하는 것(하이퍼 파라미터 값 확정에 이용됨)

하이퍼 파라미터 튜닝 아직 안배움

feature selection
컬럼 중 모델에 도움이되는것 골라내는 과정
->에도 k-fold 쓴다.

오늘 중요한 내용들 많이 배웠대
다양한 데이터셋으로 연습할 것
