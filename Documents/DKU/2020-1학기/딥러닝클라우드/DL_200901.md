# 목차

[200901](#200901)

[200911](#200911)

[200915](#200915)

[200922](#200922)

[200929](#200929)

[201006](#201006)

[201013](#201013)

# 200901

## 수업 개요

### 교과목 목표

- 딥러닝의 기본 개념
- 딥러닝을 현실 문제에 적용할 수 있는 방법론 학습
- 카페(Caffe), 텐서플로우(Tensorflow) 등 주요 딥러닝 프레임워크
- 클라우드 환경에서의 데이터 처리

### 기대되는 학습성과

- 파이썬의 딥러닝 관련 라이브러리 활용 가능
- 머신러닝의 개념 이해(딥러닝보다 넓은 차원의 개념)
- 클라우드 컴퓨팅의 종류와 동작 방식
- Keras(프레임워크)를 이용해 딥러닝 문제를 해결

1주차

## Deep Learning

인공지능: 기계 등이 인간과 같은 지능, 판단 할 수 있게 하는 -> 이것의 연장선상에 딥러닝이 있음

![image](https://user-images.githubusercontent.com/33214449/92207133-b28f7180-eec3-11ea-9a91-68d3b779d290.png)

출처: https://www.datacatchup.com/wp-content/uploads/2019/05/image.png

## Cloud

온프레미스
IaaS
PaaS
SaaS

![image](https://user-images.githubusercontent.com/33214449/92207542-5aa53a80-eec4-11ea-97d9-d8a2d433cffd.png)

## 실습 환경

PC - Anaconda 를 이용해 Python 사용할 것
Cloud - GoogleColab

# 200911

2주차

## 주의

문법 위주의 설명. 강의에서 코드실행은 하지 않으니 코드를 실행해볼것

파이썬은 인터프리터 언어(컴파일 과정이 없음. 라인바이라인 실행. 명령어를 치면 바로 결과를 확인할 수 있는)

텐서플로같은 잘 알려진 딥러닝 라이브러리를(API를) 파이썬이 지원함
딥러닝, 머신러닝할 때 데이터를 다루는 것이 중요한데 파이썬은 numpy같은 라이브러리를 제공하고 다루기가 용이

5페이지

제곱은 \*\*

7페이지

파이썬은 명시적인 변수 선언이 없다

초기화를해야 변수를 쓸 수 있음

변수의 값을 확인하는 방법

- 1. 명시적으로 print
- 2. 변수명만 입력해도 변수의 값이 출력됨

2번째 강의 ~

8페이지

따로 char 없음
bool형은 대소문자 지켜서 쓰기 (True, False)

12페이지

`{0}` 여기에 어떤 값이 출력되는데 뒤에서 보면 x가 넣어지는 것

13페이지

`{0}` `{1}` `{2}` 안에 숫자는 인덱스를 나타내는 것

14페이지

뒤로가면 리스트보다 편한 거 쓰지만 알아야되긴하니까 함

17페이지

range()
뒤는 +1임 기억
range(5,10) 5~9까지 만듬
range로 만든 요소값은 변경 불가

18페이지

range 형을 list로 바꾸면 요소를 수정 가능

시작 숫자 생략하면 0부터 시작되는 수열
range(10) : 0~9

19페이지

tuple -> 잘 안씀 그냥 넘ㅇ어가~

a = (1) 이렇게 쓰면 int로 인식

3번째 강의~

22페이지

같은 깊이로 들여쓰기 할 것!

23페이지

and or

24페이지

enumerate 열거형
순서는 i, 실제 값이 들어오는건 n

25페이지

numpy 넘파이를이용한 배열
파이썬 라이브러리-> 모듈이라고 부름
리스트도 있지만... 넘파이는 배열을 쉽게 다룰 수 있게 해줌
리스트보다 처리 속도가 50배정도 빠르다
n차원의 배열을 선언할 수 있다.(넘파이에서 배열객체를 ndarray라고 함)

26페이지

넘파이에서 1차원 배열은 vector라고함

28페이지

numpy.arange

29페이지

벡터연산(리스트와 차이)
배열과 배열의 덧셈이 됨(c언어라생각하면 for문 돌려서 해야됐을것)
연산하려면 차원이 같아야됨

30페이지

2차원->array

array 의 크기
2행 3열 의미
dtype 데이터 타입!

4번째 강의~

31페이지

2행 10열의 배열이 생성됨

32페이지

rand 0에서 1사이 랜덤한 거 나옴

(seed 같으면 랜덤하긴해도 내가하든 남이하든 같은 랜덤값
seed 다르면 매번 다른 결과)

33페이지

reshape 원소의 총 개수는 같아야 사용 가능
벡터를 차원으로 바꿀 수도 있음, 2차원도 옆으로 늘려 벡터로 만들 수도 있고

36페이지

배열값 각각에 대해서 수학 연산 할 수 있음

37페이지

행렬곱셈 의 의미(딥러닝에서 많이 쓴대)
v.dot(w)

w.dot(v) 와 결과 다름

38페이지
잘라내 여러개 추출할 수 있다

[:5] 처음부터 5인덱스 바로 전까지 자름
[2:5] 인덱스 2 부터 인덱스 5전까지. 즉 인덱스 2,3,4

[n:] n부터 끝까지 다

39페이지

[:,1] 행은 처음부터끝까지, 열은 1행만

41페이지
함수에 대해서 알고싶을 때

43페이지

파이썬에서는 리턴값을 여러개 줄 수 있음

(파이썬은 블록단위로 다른문장 먼저 실행하면 그 데이터 갖다쓰는 코드 그다음에 실행해도 실행되네)

44페이지
배열의 값을 파일에 저장해놓을 수 있음(중요한 결과값이라면 이런 과정 필요!)

45페이지
많이쓰진 않음

# 200915

3주차

chap03_1,2,3 부분 피피티 다시 정독할 것

## 수업 개요

- AI scopes
- Machine learning
- Machine learning areas
- Development process of learning model
- Sciket-learn

## DC_chap03_1_compact

3페이지
머신러닝은 독립적인 분야라기보다는 많은 것과 관련되어있다(인공지능에 속하고, 패턴 인식, 통계학, 시각화 등과 관련 있음)

4페이지
머신러닝 이나 데이터마이닝 겹치는 부분 있어. 대량의 데이터가 관여된다.
데이터마이닝: 정보를 뽑아내는
머신러닝: 데이터를 토대로 예측하는

5페이지
인공지능: 컴퓨터가 사람처럼 행동하게끔 할 수 있게하는 기술
머신러닝: 통계적인 방법과 데이터를 활용해 문제를 더 잘 해결하게끔하는 인공지능 기술
딥러닝: 뉴럴 네트워크

6페이지
머신러닝이 뭘까? 머신이 기계일까 학습한다는 것은 무엇일까?
구체적으로 뭘 한다는 것일까?

7페이지

머신러닝 (실제적인 의미): 과거의 경험을 미래의 결정(예측)에 활용하는 소프트웨어를 디자인하고 연구하는 분야

=>과거를 공부해 미래를 예측하는 기술
과거 데이터로부터 숨겨진 규칙을 찾아내 일반화-> 이를 미래 예측에 활용

과거의 경험 자체를 잘 이해하는 것 유용한 정보를 뽑아내려고 하는 것=> 데이터 마이닝
여기서 규칙을 찾아 미래 예측에 활용하려 하는 것은 머신러닝

전통적 SW
규칙을 인간이 알아내어 알고리즘 형태로 SW 안에 구현한 것(이게 규칙이겠지~)
누가 알고리즘을 잘 만드느냐가 SW엔지니어의 능력이었음
(알고리즘은 규칙을 찾아가는 과정을 다 서술한 것)

머신러닝
규칙을 알아내는 방법은 인간이 제시(방법론만을 제시)
머신이 규칙을 찾는다. (전통적 SW 와의 차이)
머신이 과거데이터로부터 규칙을 알아내는 과정이 '학습'(머신입장에선 학습, 인간입장에선 머신을 '훈련'시키는 것)

인공지능 > 머신러닝 > 딥러닝 (포함관계)

머신러닝: 과거의 축적된 데이터를 '학습'하여 미래를 예측하는 기술

8페이지

머신 러닝은 기본적으로 데이터가 있어야한다.

예측모델 -> 규칙을 의미 (어떨 때 주가가 이렇더라)
이제 데이터가 있고 내일 주가를 모르면 그 데이터를 모델에 넣어 주가 예측할 수 있는 것

9페이지

머신 러닝에서 '머신' -> SW, 프로그램

10페이지

머신러닝이 사용하는 학습 자료는? 데이터
엑셀 형태의 데이터. sns에서 오가는 데이터들, 이미지, 음성파일 등

11페이지

'러닝'은 무엇인가?

설명변수:아까 본 주식에 영향을 미치는 요인들(여러개)
반응변수:요인들에 의해 결정되는 주가(하나)

잘 정돈된 데이터인 데이터셋(설명변수, 반응변수)를
학습방법에 집어넣으면... 러닝이 됨(머신입장)
학습의 아웃풋은 예측 모델이라함

12페이지
러닝의 사례들

13페이지
이런 학습 알고리즘을 잘 사용할 줄 알면됨

15페이지
관건은 얼마나 정확한 모델을 만드느냐가 관건

## DC_chap03_2_compact

17페이지

우리수업에선 지도학습 주로 학습(비지도학습은 조금, 강화학습은 다루지 않음)

- 지도학습 (가이드하는 학습방법)
  문제, 답을 같이 줘서(설명변수, 반응변수를 같이 주고) 학습시키는 것이 지도학습

  - 회귀(답의 형태가 수치형. 값이 있고 크기 비교가 가능한)
  - 분류(답이 범주형.)->수업에서 제일 많이 다룰 것

정답의 형태에 따라 회귀, 분류로 나눠짐
맞추고자하는 답의 형태가 수치형이면 회귀
(분류문제 가장 많이 다룸)

- 비지도학습
  문제만 주고 답은 안줌

18페이지

세모를 모델에 넣으면 -인지 +인지 알려주는 (분류의 예)

처음엔 그룹이 뭔지도 모름
그룹이 어떻게 구성되는지 찾아봐라(군집화)

위 둘의 차이는
분류는 그룹 정보가 이미 주어진다.
군집화는 그룹 정보 없이 스스로 그룹 정보를 만들어내야함

19페이지

오존이 120 일때 기온은 얼마일까? 예측 가능
예측해야될 대상이 클래스나 범주가 아니라 숫자라면
regression

20페이지
처음에는 비실비실한데 나중에는 잘 치게 됨

## DC_chap03_3_compact

요 영상 중요하대

22페이지

개발자 입장에서 어떻게 모델을 개발하는지 과정 도식화한 것

학습에 사용할 training data
학습에 사용하지 않는 test data 로 나눔

만든 모델의 성능을 평가하는 것이 굉장히 중요
(평가를 어떻게 하지? 어차피 미래를 예측하는 건데?)

test data가 미래 데이터로 보고
학습에 안쓴 test data를 미래 데이터로 보고 이걸 가지고 예측해 예측 결과를 도출.
그리고 test data는 이미 결과를(Y) 가지고 있으니까 예측한거랑 이거랑 비교해서 모델을 평가

validatoin data 는 현재 이루어지고 있는 학습 과정이 잘 가고 있는지를 평가하기 위한 데이터이다.(부족한 부분 보충) 어떤 모델은 이게 있고 어떤 모델은 없는 알고리즘도 있음

---

머신러닝의 아웃풋은 '학습 모델'

22페이지 표 자주 나올 것

test data(일부 남겨놓은)를 미래 데이터로 보고
그 학습과 학습시킨 모델과 비교

비교해 많이 일치할 수록 모델이 정확도가 높다 이렇게 판단할 수 있음

---

24페이지

각각 모델 의 결과와 이미 있는 결과(Y)를 이용해 accuracy 도출 가능

왜?
training data를 통해 학습했기 때문에 training accuracy 정확도가 높음

## DC_chap03_4_compact

파이썬에서 머신러닝을 위해 사용되는 두가지 라이브러리 소개할 것

25페이지

1. sciket-learn (라이브러리1)

여기 있는 함수 많이 배울 것

26페이지

2. pandas (라이브러리2)

학습에 쓸 데이터가 보통 파일에 저장되어있는데 그걸 불러와서
데이터 프레임(넘파이에 있는 것 처럼 2차원 배열같은)에 저장할 수 있음
그리고 그 데이터프레임을 가공 가능(어디부터 어디까지 잘라서 쓰고 등등)

27페이지

꽃받침의 길이와 너비, 꽃잎의 길이와 너비(x) 주고 이게 품종(y, 결과)이 뭘까? 분류할 수 있을것(이 학습데이터를 바탕으로)

28페이지

iris 가 데이터프레임을 담고있게됨

with display.max... 생략된 데이터 없이 행, 컬럼 다 보일 수 있게함

head() 데이터를 앞부터 몇개만 보고싶을 때
인수로 숫자를 주면 몇개도 설정가능

tail()은 그 반대

iris.shape 행과 열만 알고싶을 경우

columns 컬럼의 이름을 보고싶은경우(컬럼은 실데이터는 아님)

columns[:4] 앞에서 시작해 4번째까지(0,1,2,3)

iris['컬럼이름'] 해당하는 컬럼 데이터만 가져옴
iris[['컬럼이름', '컬럼이름']]
이렇게 잘라내고 또다른 변수에 저장해 데이터프레임처럼 쓸 수 있음

iloc도 기준이 행은 인덱스고 열은 0부터시작하는 값인듯
iloc 인덱스를 이용해 자르는 방법
iloc[90,4] 인덱스 90에 해당하는 행과 4에 해당하는 열 -> 열도 0부터시작하니 실제론 5번째 열에 있는 데이터가 나올 것

iloc[10:50, 0:4] 10~50 행, 0~4열에 해당하는 데이터 가져오는
iloc[10:50, :] 10-50 행, 열은 모두 라는 의미

조건을 주고 자르는 경우
논리식은 데이터마다 t, f 판별한 정보 가지고 있음
iris[setosa] 품종이 setosa 인 것만 보여줄 것
& -> and의미 두 조건을 만족하는 것만 골라오는 것

30페이지

어떤 모듈 설치되어있는지 확인 가능한 명령어

# 200922

## 수업 개요

1. Simple linear regression 단순 선형 회귀
2. Multiple linear regression 다중 선형 회귀
3. Logistic regression

회귀문제 이면서 분류도 풀 수 있음 오늘 다룰 것

## 수업 내용

### DC_chao04_1_compact

1. Simple linear regression

4페이지

독립, 종속 변수의 두 관계가 선형관계인지 파악하고(하나 증가하면 다른 하나도 증가하거나 하나 감소하면 다른 하나도 감소하거나) 이를 예측에 활용하는

모델 = (구체적으로 말하면)학습 모델

머신이 W,b 같은 상수를 알아내게 하는게 목표임

6페이지

산점도

오른쪽 두개는 선형관계가 아닌 경우임

오른쪽위는 이차식이 될 것

왼쪽것에 단순선형회귀를 적용할 수 있다.

7페이지

(a) 가 더 좋아보이는데
이걸 객관적으로 평가할 수 있는 척도가 필요함

8페이지

오차들의 합계가 가장 적어야함

예측값-실제값이 마이너스인 경우도 있고 플러스인경우도 있음
그래서 각각을 제곱해서 더해줌.

12페이지

regression 하려면 넘파이 배열로 담아줘야함.
그리고 reshape으로 2차원 배열이 되도록해줘야해(여기서는)

13페이지
test_size=0.2
test data를 20프로로 하겠다는것(그럼 training data는 80프로가 되겠지)

random_state 랜덤 시드값 (실행시마다 랜덤으로 정하는 것 고정시키려고)여기선 train test 나누는 것을 랜덤으로 햇을때 그걸 이후에도 사용하기 위해서

14페이지

모델만들 때 방법 지정

fit=learning 학습하여 W,b얻을 수 있음

predict로 예측
pred_y랑 test_y랑 비교해서 정확한지 보면되겠지

15페이지

값 하나로 예측하고 싶을 때(곽갈호 2개인 것에 유의-predict가 2차원 배열을 받아들이기 때문에)

16페이지

실제는 아래 코드처럼 써야함

W,b 출력할 수 있음(학습이 끝난 모델안에 들어있는 것)

17페이지

모델 평가 1

mean squared error
실제값-정답값 의 제곱을 더해 평균낸 것(오차의 제곱의 합 평균)
이 값이 작을 수록 정확한 모델

0이면 예측이 정확하다는 것인데 이는 이상적인 값

근데 이 오차가 얼마나 작은것인지를 추측하기가 힘듦

18페이지

모델 평가 2

r2 score
1에 가까울 수록 좋은 모델인 걸 알 수 있기 때문에 모델 평가 1보다 보기 쉬움

19페이지

scatter 산점도 그리는 것
plot 라인 그리는 것

### DC_chao04_2_compact

2. Multiple linear regression
   중 선형 회귀
   다중 선형 회귀

20페이지

독립변수가 2개 이상인 경우(단일 선형 회귀와의 차이점)

intercept 편차

22페이지

c income 연봉을 예측하고싶음(선형)

교육년수, 여성비율, 직업에 대한 평판 쓸 것

26페이지

단순 선형 회귀와 코드 방식은 비슷

27페이지

독립변수가 3개라 coefficient계수도 3개가 나옴

28페이지
각괄호 2개 해도 되고
이렇게 reshape 써도 되고

### DC_chao04_3_compact

3. Logisic regression

분류 문제를 회귀 방법으로 풀려고 하는 것

30페이지

이것도 어차피 회귀라 품종도 숫자로 나타내야함

33페이지

전체 정답중에 정답을 맞춘 개수

분류가 logistic regression 보다 성능 좋지만 배우는 건 필요하니까!

# 200929

5주차

## DC_chap05_1_compact

1. remind: clustering, classification

3페이지

clustering(군집화)
비슷한 데이터들끼리 묶는 작업
(알아서 묶음)비지도적 학습
거리가 가까운 것들끼리 묶음-> 거리계산이 중요

4페이지

classification 분류
이미 범주를 알고 있음
남자 / 여자 나눌 때 어떤 정보가 남자인지 여자인지 구별
예측, 진료에 많이 쓰임
이 수업에서 많이 배울 것
지도적 학습(이미 범주데이터-정답이 주어지기 때문에)

6페이지

이렇게 그룹을 만들어 해석.
속도는 느리고, 무게는 무겁고...~~~ 아마 화물차일것

그룹지어짐>특성 존재

7페이지

환자와 정상인
아래 데이터를 보고 어떤 범주(환자or정상)에 속하는지 구하는

8페이지
분류는 이미지를 가지고도 할 수 있다.

사진속 장소 이름 뭔지 모르겠을 때 > 비슷한거 찾음

9페이지

분류가 두개일 때 -> binary

multiple
알파벳은 스물 몇개겠지(클래스가)

binary vs multiple 뭐가 쉬울까?
binary가 쉽겠지. 찍어도 50프로니
모델의 정확도가 비교적 높다는 뜻

## DC_chap05_2_compact

2. k-means clustering

11페이지

서로 다른 주파수대역에서 음파를 측정
금이가고 안간 타일을 구분하기 위해

군집화해서 금간것끼리 금안간것끼리 묶여야 사용 가능

12페이지

로그값을 취해 값을 좀 줄여줌(logarithms)

k=>클러스터의 개수
금이간 타일 정상 타일 예는 k=2이겠지

14페이지
가상의 점 k개 찍기
-> 각 클러스터의 중심점이 될것
이 점들과 나머지 원래 데이터들의 각각 거리 측정
(각각의 점이 가상의 점들 중 뭐랑 가까운지 계산하고 그룹화)
더 가까운 점을 포함시켜 중심점 계산(x좌표 다 더하고-가상 점 포함- 점 개수만큼 나눔.)

![image](https://user-images.githubusercontent.com/33214449/95008868-68cbaf80-0658-11eb-80a2-c8945025af8c.png)

15페이지

14페이지 반복

22페이지
labels
각 데이터의 클러스터 뭔지

붙여서 잘 보여주려고 한것
hstack 수평으로 쌓기

reshape(-1,1) 행은 너가 알아서 맞춰 라는 뜻
21페이지에 있는 데이터랑 붙이려면 reshape 해줘야해(세로로 세우는 작업)

cluster_centers 중심점
첫번째께 0번 클러스터, 두번째께 1번 클러스터

[0,0]은 어떤 클러스터일까 이렇게 추측해보는 것 (predict)

## DC_chap05_3_compact

3. KNN classifier

25페이지

별 데이터는 동그라미인지 세모인지 모른다고 할 때

knn
모르는 데이터에 가까운애들을 줄임(7-nn)
그중 많은 클래스를따른다.(여기선 동그라미)

26페이지

클래스수가 동수일때는 어떻게하나?
K를 몇으로 해야되나 이슈가 발생

27페이지

거리계산은 k-means에서 봤던 식과 같음

28페이지

루트 n보다 작게 k를 잡아라

29페이지

색깔있는 숫자가 정답

아래 색깔 그려진건 예측값

k숫자가 커질 수록 예측값 정확도가 점점 떨어짐을 볼 수 있음

k 1,3,5 다 해보고 제일 정확한걸 고름
하이퍼파라미터: 모델을 만들 때 모델의 정확도(성능)를 결정하는 몇가지의 변수들을 의미(knn에서는 하이퍼 파라미터가 k 하나겠지)

30페이지

데이터 분포가 어떻든지 분석 가능(통계적 가정 불필요)

데이터 커질 수록
새로운 데이터를 데이터들과 거리를 계산해야되서
데이터를 메모리에 다갖고있어야됨

계산도 많이해야되니까 처리시간 증가

32페이지

k값을 3으로 줌

fit함수 -> 학습하는 것

classfication 분류에서 모델 성능 평가시 많이 쓰는 것 accuracy
(전체 테스트 데이터 갯수중에 정답맞힌 갯수)

34페이지

ex예로 거리를 계산해보면
실제로 차이가 많이나는 건 시력인데(1.0 과 0.1)
거리 값에 영향을 크게 미치는 건 키 값임을 알 수 있음
둘의 스케일이 다름

키도 0~1로 시력도 0~1로 동일한 영향력을 갖도록 스케일링을 해줘야함

kmeans knn 하려면 스케일링 해야함

## DC_chap05_4_compact

4. perfomance metric

37페이지

성능 평가!

binary classification의 경우 이런 성능평가 척도 가지고 있다.(why 모델이 어디 적용되느냐에따라 다양한 것이 사용됨)

38페이지

T : 잘 맞춘것

FP,FN은 오류
FN이 더 심각하지(코로나라고 생각하면)

accuracy는 경우중에 정답인 것만

39페이지

민감도
ex) 양성인 사람중에 양성이라고 예측한 비율

특이도
ex) 음성인 사람중에 음성이라고 예측한 비율

의료환경에서는 무엇이 중요할까? 민감도가 중요할 것.(환자인데 음성이라고 진단한 경우가 높으면 큰일이니)

40페이지

정밀도

양성이라고 예측한 사람들 중에 진짜 양성인 사람

41페이지

f1 score
민감도와 특이도의 불균형 측정

민감도가 100퍼센트인데(1) 특이도가 0이면 f1 score는 0

불균형한 경우 척도값이 낮게 나오는게 f1 score

42페이지
class가 3개이면 성능 측정 어떻게 하나?
(multiple class model)

클래스별로 민감도 특이도를 계산할 수 있으나 잘 쓰지 않음

43페이지

classification에서 쓰는 척도들

모델을 만드는 것도 중요하지만 성능을 측정하는 것도 중요

45페이지
인자 줄 때 정답이 앞에 예측이 뒤에 와야됨!

46페이지
3x3행렬보면...
test_y가 정답임

정답은 0 인데 예측도 0으로한건 2개라는 뜻
대각선이 제대로 맞춘 것들을 나타냄

## DC_chap05_5_compact

5. k-fold cross validation

validation이니까 평가해서 알아보는 것임

이 결과를 믿어야할까?라는 것
training , test 데이터를 어떻게 나누느냐에 따라 정확도가 엄청 달라질 수도 있음

-> 해결하려면
나누는 걸 여러번 해서 평균을 할 수도 있음
아니면
k-fold cross validation사용

50페이지

k=4면 전체를 4등분하는 것

ex1에서 진한걸 test, 나머지 training
ex2도
ex3도
ex4도

각각의 accuracy를 평균하고
이걸 그 모델의 accuracy로 보자는 것

k=10이면
10번 나누겠지
10번 모델을 만들거고

51페이지

랜덤하게 나누니까 random_state 줘야함(이후에도 같은 결과 얻으려면)
shuffle 데이터를 마구 섞고 등분할거냐 물어보는 것

knn사용한 것

accuracy 저장할 크기 5인 배열 선언

53페이지

np.mean 평균

54페이지

좀더 단순한 방법

fold쓰지 않고 cross \_val_score 사용

단지 accuracy만 구하기 때문에 사이에 코드를 넣으려면 전 페이지처럼 자세하게 하는게 좋을 수도

55페이지

k-fold
원하는 모델을 도출하지는 않음(모델 여러개 나오잖아)
정확도를 추정하는 용도

knn쓴다했을 때
k정해야함. 여러번해서 좋은거 써야함
이때 k-fold 써서 k가 몇일때 정확도 몇이고 이런걸 구하는 것(하이퍼 파라미터 값 확정에 이용됨)

하이퍼 파라미터 튜닝 아직 안배움

feature selection
컬럼 중 모델에 도움이되는것 골라내는 과정
->에도 k-fold 쓴다.

오늘 중요한 내용들 많이 배웠대
다양한 데이터셋으로 연습할 것

# 201006

6주차

classification(분류) 방법 중 하나인 의사결정나무(decision tree) 학습할 것

## DC_chap06_1_compact

3페이지

분류에서 학습함이란,
클래스를 나누는 경계를 얼마나 잘 찾느냐(직선, 곡선 얘기)
3차원이 되면 면이 될 수도 있기 때문에 hyper plane이라고도 함.(클래스와 클래스의 경계)

4페이지

분류를 할 수 있는 많은 방법이 있음

svm
decision tree
random forest
주로 배울 것

xgboost 요즘 많이 쓰는. 수업에선 소개만 할 것

머신러닝처럼 노가다도 이런 노가다가 없다 그렇게 느끼게 될 것임

## 1.Decision Tree

5페이지

x1, x2값을 주고 색깔을 예측하는 결정 트리
sibsp 가족수

9페이지

decision tree 가 경계를 찾는 과정 배울 것

step1
일단 먼저 특정 두 클래스를 구분하는 선을 찾음

11페이지

전 페이지에서 보면 일단 split1 기준

(차지하는 수 / 전체 경우의 수)

celebrities(유명인사, 탑급배우) 나누는건 앞페이지에서 처음에 나눈 split1 선 기준으로 생각하면 됨(y축)

budget(예산)

12페이지

어떤 속성부터 선택할 것인가가 문제가 되는데...
고혈압 vs 정상 일때 두 클래스의 겹쳐지는 부분(교집합)이 제일 작은 것을 루투노드로 사용한다.(여기선 몸무게겠지)

13페이지

split을 언제 중단할 것인가(몇개까지 나누느냐)
경계선을 많이 나누면 예측은 정확해지겠지만, overfitting 발생(과적합) test데이터로 학습을 하면 예측이 떨어질 수도 있음. 적당할 때 트리 생성을 중단할 수 있어야함(과적합은 다음 시간에 배울 것)

14페이지

명목속성(범주형 자료)
속성(컬럼)

단점
훈련 데이터가 조금만 바껴도 트리가 크게 달라질 수 있음

대각선은 만들 수 없대 이게 단점!

## DC_chap06_2_compact

19페이지

category 클래스 정보
drinks 알코올

간 질환 있는지 검사하는 것이 목적

20페이지

df_X 코드부분 -> category가 아닌 것들만

22페이지

decisiontree 만들 때 랜덤하게 선택하는게 들어가기 때문에 random_state 값 줘야함(모델 정의할 때. 지정하지 않은 값은 디폴트값이 들어감)

train accuracy 1.0나왔는데 이건 100퍼 라는 뜻

confusion_matrix
23, 14가 에러고 나머지 대각선은 뭐라는데 모르겠음

23페이지

모델 정의시 인자 더 줄수도 있음
트리 깊이를 4로 제한.(자식이 생길 때마다 깊이가 1씩 늘어남)

트리깊이 적용했더니
test accuracy는 성능이 더 좋아졌음.

15,17 -> 32개의 오류 발생.(22페이지보다 좋아졌음)

-> 매개변수를 잘 조절하면 모델의 성능이 좋아질 수 있다.(다른 매개변수도 조정해 최상의 결과 내는 게 목표)

26페이지

하이퍼 파라미터
:모델 성능에 영향을 미치는 매개변수

min_samples_split
0~1 사용해 퍼센트로 줄 수도 있음
가지 분리시 각각 분배될 수 있는 최소 샘플수(10개를 두가지로 분리시 분리되고 나서 있을 수 있는 최소 샘플수)

27페이지

min_samples_leaf
하나의 노드가 가지고 있어야할 최소 샘플 수

max_features
컬럼을 모두 쓰진 않는다고 했지. 컬럼중 몇개로 제한할 것이냐

class_weight
클래스의 중요도
환자가 환자로 판명되는게 (반대보다) 더 중요하니까 (그런말임) 안그러면 큰일나자녀

⭐ 모델 만들 때 다양한 매개변수 줄 수 있음

중요한 것

- 어떤 모델을 쓸 것이냐
- 방법론이 결정됐을 때, 매개변수를 어떤 걸 지정해서 모델을 만들 것이냐

여러가지를 시도해봐야 어느방법, 어떤 방식이 좋은지 알 수 있음.

## DC_chap06_3_compact

## 3.Random Forest

29페이지

결정 트리를 응용한 개념

트리를 하나가 아니고 여러 트리를 만들어보자는 것

그럼 예측은 어떻게 하느냐
정답을 모르는 값을 트리1에 넣어보고
트리2에도 넣어보고
트리3에도 넣어보는
결과중 가장 많은(다수결)결과로 결정해서 예측하는 것

트리를 만들 때 랜덤하게 만들기 때문에 random forest

bagging
모델을 여러개(n개)를 만들어서 각각의 모델의 결과들을 취합해서 결과를 내는.

random forest는 bagging을 구체적으로 구현한 한 방법이다 라고 볼 수 있음

30페이지

bagging
데이터 인스턴스도 샘플링하고
컬럼도 샘플링한대

33페이지

n_estimators 트리의 개수 몇개로 할 건지

34페이지

트리 개수 올리니 성능 더 좋아졌음

매개변수의 값을 바꿔가면서 모델 성능을 향상시키는 방법을 하이퍼파라미터 튜닝, 모델 튜닝이라고 함.

35페이지

중요한 파라미터들을 적용하는 것이 필요
(파라미터 많아지면 튜닝 시간 길어지니)

## DC_chap06_4_compact

## 4.Support Vector Machine

37페이지

두 아이디어가 사용 1)경계선을 찾을 때 (모든 점의 정보를 이용하지 않고 경계면에 있는 몇개의 점을 이용해서 찾는다)클래스와 클래스 사이에 몇개의 점을 사용해 경계를 찾는 것. 그 몇개의 점을 support vector라고 함
-> 클래스 주어졌을 때 이 서포트 벡터를 어떻게 찾아내느냐가 관건

2. 2차원을 3차원으로 변형하게 되면 더 쉽게 나눌 수도 있음. 차원을 하나 높여 경계(면)을 찾아보자. (차원을 하나 높이는 방법이 kernel이라고 함)

38페이지 이론적 내용이라 스킵

39페이지

svm.SVC 분류(classification)에 많이 쓰임

40페이지

libsvm을 파이썬으로 재구현한 것
학습시간이 데이터셋의 샘플 수의 제곱수준으로 학습시간이 길다. (인스턴스가 많아지면 학습시간이 지수적으로 증가. 특정 개수 만개 넘어가면 실용적이지 않대 오래걸려서. 교수님은 만개정돈 괜찮대)

너무 오래걸리면 linearSVC이런거 고려해봐라는 지침

43페이지

매개변수
kernel 데이터셋의 차원을 높이는

모델 성능 떨어졌네

44페이지

c, kernel 주목!

C:
과적합이 일어나지 않도록 조절하는데 쓰이는 매개변수

kernel:
데이터셋의 차원 변형하는

degree는 poly 쓸 때 의미가 있음
다항식의 항의수?..

gamma
커널이 rbf, poly, sigmoid 일 때 의미가 있음
커널의 coefficient값을 정해주는

45페이지

여기만 봐서는 뭐가 좋은지 잘 모를 수도 있음
accuracy 확인 필요

1보단 2가 나은듯
3은 파란부분 잘 분류됐고 괜찮은듯
4는 이런식
1,2 보다는 3,4가 좋아보이는데 정확한건 accuracy 확인 필요 -> 실습통해 확인하기

46페이지

오랫동안 사랑받은 모델링

모델이 왜 이런식으로 결과를 내는지 해석이 어렵다.

## DC_chap06_5_compact

## 5.xgboost

48페이지

앙상블(여러개 모델을 만들어서 이를 통해 단일한 결과를 내도록하는... 예측 성능을 높이는 방법론)
그 중에 bagging, boosting 이 있음

bagging
모델을 여러개 만들어서 투표해서 결과를 내는.

boosting
예측 잘 안되는 그룹을 가지고 잘 될 수 있도록..
잘 안되는거에 중점을 둬서 이걸 예측을 잘해내면 점수를 더 주는
여전히 안되면 그걸가지고 또 모델을 만들고
... 그러면 모델이 업그레이드 된다
여긴 투표라는게 없음

49페이지

예측력이 평균적으로 최강이래 xgboost가!
복잡하긴 함
사이킷런 안에는 포함되어있지 않은 상황

50페이지

혼자 공부하려면 이런식으로 설치해서 써봐

## 6번 과제

Q1에서

scaling 작업을 해야 kfold를 할 수 있는 걸 알게됐음. scaling 복습 필요

# 201013

- 수업 내용

## DC chap07 01 compact

## 1. Bias-Variance trade off

3페이지

편향 분산 trade off
머신러닝 교재에서 중요한 부분으로 항상 다루는

예측모델의 에러와 관련이 있음

3가지 요인에 의해 모델의 예측 에러가 발생한다
3가지:
noise(제거 불가능한 에러 ex.이미 데이터에 잘못 기록한 경우. 환자가 아닌데 환자라고 기재했다던가. 원래 데이터 자체가 오류 담고 있는 경우)
bias(은행에서 돈 빌려줄 때 갚을 수 있을것인가 아닌가 예측하는데 예측으로는 갚을 수 있는데 갑자기 도산해서 못갚는 경우.. 이런 특이한 사례도 있음)
variance(분산)

대처할 수 있는 건 bias, variance

bias
ex.전체 중에 일부만 열심히 학습하는
전체 정보를 골고루 학습하지 못해서 에러를 증가시키는 현상
과소적합 유발

variance
데이터의 너무 세세한 부분까지 학습해 새로운 데이터 추가시 모델 변동성이 커지는
ex. 한 사람한테 너무 세세하게 맞는 옷 학습. 조금만 다른 사람와도 옷 안맞는걸로 예측
과적합 유발(저번에 한번 언급한적있지!)

4페이지

bias와 variance를 동시에 줄이는 모델을 만들 수는 없다.(trade off)

bias가 높은 ex)옷이 너무 딱맞아
variance가 높은 ex) 옷이 그냥 자루같은

오버피팅: 모델이 너무 복잡할 때
언더피팅: 모델이 너무 간단할 때

## DC chap07 02 compact

## 2. Hyper Parameter tuning

8페이지

하이퍼 파라미터 튜닝하면 좋은 모델이 나오지만(성능 좋은)
고된 작업이 되기도 한다.
좋은 모델을 찾는 것은 그 모델에 적절한 하이퍼 파라미터를 찾는 작업이다.

파라미터에 대한 조합으로 모델 만들때
k-fold cross validation 많이 사용

9페이지

하이퍼파라미터튜닝 = 최적화

random forest를 예로 한 것

10페이지

하이퍼 파라미터 튜닝을 위해 제공하는 것들

randomized : grid search를 변형한 방법?

12페이지

13페이지

pprint 프린트를 이쁘게

폭은 80, 들여쓰기 4

16페이지

grid search cv 사용해보자!
6가지 파라미터에 대해서만 튜닝을 해보겠다는 것

n_estimators 트리 몇개할건지(random forest 방법)

20페이지

2880개의 조합을 학습한 것이다 라는 것
5 fold 이고...

best*params* 베스트 조합!

21페이지

정확도 낮은 이유는
파라미터 경우의수가 작기 때문. 이걸 늘리고 하루? 오래 결과 기다리면 정확도 더 올라갈 수 있을 것

22페이지

random search cross validation

gridsearchcv는 모든 조합인데
randomizedsearchcv는 랜덤하게 골라서 하는 것(장점: 시간이 줄어듦)

25페이지

그리드와 차이점

24페이지

이렇게 변수를 지정하여 파라미터쪽에 넣어줄 수도 있음

200부터 2000까지를 10개로 나누어서~

linspace 10부터 110까지 11개로 나눔

이렇게 넣어서 조합의 일부만 랜덤으로 꼽아 사용

26페이지

n_iter 조합에서 몇개를 고를 건지
random state 조합에서 랜덤하게 뽑으니까 이를 고정하기 위해

27페이지

500개중 100개만 고름

28페이지

1프로 정도 성능 향상됐음 알 수 있음

⭐연습해보기

## DC chap07 03 compact

## 3. Model comparison

모델 비교

30페이지

모든 데이터셋에 대해 좋은 성능을 보이는 짱짱 알고리즘은 없다.
다양한 알고리즘을 써서 테스트를 해야함(가능한 많이)
그럼 쉽게 테스트할 수 있는 방법은 없을까?->사이킷런에서 제공

31페이지

labelencoder 문자열-> 숫자
당뇨. 레이블 데이터 가 지금 문자열이니까 숫자로 바꿔주려고 쓰는 것

32페이지

logistic regression은 숫자로 바꿔줘야하기때문에 encoder 사용(다른 알고리즘들은 괜찮지만)

33페이지

append 차곡차곡 넣음

인자는 두개
약칭, 모델

34페이지

result 모델 테스트할 때 나온 accuracy 결과 저장하기 위해

scoring 평가방법은 accuracy로 하겠다

kfold로 랜덤하게 나눔

cv_results~
이 모델의 cross val score를 구해라
사용할 모델, 데이터는 이렇게 주고 , cv는 세팅한 kfold로, 성능평가할 척도는 scoring에 저장되어있다

kfold로 했으니까 accuracy가 10개가 나오겠지 그래서 이거의 평균(mean)구해주는 것

std() 표준편차

35페이지

\t 로 (탭) 줄 맞춰주고
평균값만 4째자리까지 구해서 출력하는 것

36페이지

5가지 알고리즘별 accuracy

작대기 구간은 kfold로 구해진 accuracy 10개 값 범위 의미
박스 -> 그 10 개중에 가운데 5개(전체 데이터의 50프로) accuracy가 차지하는 범위
주황선 -> 중앙값(가운데 있는 값)

중앙값을 비교해 높은게 좋은 알고리즘
작대기 폭이 의미하는 바는 accuracy 변화 -> 모델의 변동 폭이라 볼 수 있음. 가장큰건 knn. lr도 큰 편. 변동폭이 큰건 좋은게 아님. 새로운 데이터 들어오면 모델이 바뀔 가능성이 높은 것. lr이 accuracy보면 가장 좋은 것 같지만 다른 rf, svm 취하는것이 더 좋을 수 있다.

## DC chap07 04 compact

## 4.feature selection

38페이지

feature=변수=컬럼(데이터셋의)

컬럼 중 일부만 사용해서 예측할 때도 있을 것
진단할 때 모두가 유용한 정보는 아닐 수도 있음
(중요도가 다를 수도 있고)

feature 중 중요한 것들을 골라 만드는 것이 중요(성능을 높이는 결과를 가져오기도함)

feature가 너무 많은 경우도 좋지 않음

39페이지

feature를 평가하는데 많은 방법이 있대. 그중에 하나 배울것

40페이지
클래스(ex. 환자와 환자아닌사람) 사이의 경계가 clear하면 좋은 feature = 교집합 구간이 짧다는 것

교집합 구간이 좁을 수록 좋을 것

실질적으로 는 filter method 사용
변수하나하나를 평가 척도에 의해 평가하는 것
평가척도 좋은 순으로 나열해 앞에서부터 n개를 선택하여 사용
단점: feature와 feature 서로 독립적이라고 가정하고 평가를 하는건데...(feature 자체가 가지고 있는 예측력만 평가하는 것- 겹치는 구간이 얼마나 작으냐) 다른 feature랑 합쳐지면 시너지를 내는 feature가 있을 수도 있음. 이를 고려하지 못하는게 단점임

41페이지

filter method -> 평가는 한번

(여러가지 고려함. filter method의 단점을 보완)
forward selection
backward elimination

실습해볼것

- forward
  좋은 애들 순으로 하나씩 가져오는

가장 좋은애를 찾음
그 다음 나머지중에 또 평가해서(상호 협력성?도 고려함) 좋은애 가져옴

끝내는 방법은 보통 2가지
개수를 미리 정하거나
정확도가 더이상 오르지 않을 때 멈추는

- backward
  안좋은 애들을 빼나가는 방법(빼는 방법도 여러가지가 있음)

언제 스톱?
개수 정할 수도 있고
빼면서 accuracy가 증가하는데 증가하는게 멈추는 부분에서 스탑할 수도 있고

## DC chap07 05 compact

43페이지

univariate feature selection -> filter method

recursive feature elimination -> backward elimination

(forward selection은 없는데 다른 모듈 써야된대)

44페이지

전체 변수 모두 사용시 정확도 구해봄

45페이지

selectkbest
각각변수중 k개 고르는

chi2 평가 척도(변수 하나하나 평가시 어떤 방법 쓸지) (카이 제곱?)

여기 예에선
shape[1] 변수의 개수 (컬럼의 개수) -> 모든 컬럼 다 선택한다는 것
(뭐하러 전체 하냐? -> 이렇게 하면 컬럼마다 평가값 알 수 있어 우리가 자의적으로 고를 수 있음)

fit.scores로 평가값보니
(chi2는 숫자가 클 수록 좋다는 것)

-fit.scores
이렇게 마이너스 주면 내림차순으로
f_order 인덱스를 정렬한 것
컬럼을 평가가 좋은 순으로 출력함
feature를 하나씩 늘려가면서 x를 지정하고 학습

46페이지

왜 df_X.shape[1]+1일까?
shape[1]은 전체 컬럼의 개수임.
아래에서 슬라이싱할때 0~i직전까지 자르기 때문인듯

47페이지

backward 방법
n_features_to_select 몇개를 남길것이냐.(여러가지 숫자로 테스트해봐야함)

어떤 feature가 선택이 됐는지(.support)
.tolist()로 예쁘게 출력

선택된 feature 만으로 accuracy 구해보는

48페이지

step
한번에 하나씩 제거할래 아님 일정 비율로 제거할래

49페이지

forward selection 사이킷런에 없기 때문에 이렇게 mlxtend 모듈 사용해야함

custom_feature_names = df_X.columns
컬럼이름을 주는것.(이걸 안하면 컬럼 index가 나온대.숫자로. 이름으로 하면 잘 알 수 있음)

50페이지

subset
과정이 다 나옴

51페이지

실습에 사용한 파라미터 정도만 사용할 줄 알면됨

53페이지

가급적 적은 변수를 이용하여 높은 정확도를 내는 것이 좋음

RFE
이용하려면 각 피처의 중요도를 기반으로 평가함
중요도 정보를 줘야해
knn을 rfe에 집어넣으면 작동이 안됨

54페이지

feature selection을 먼저 해야함

cross validation은 세 박스 때 모두 해야해

# 과제

참고

https://injo.tistory.com/10

dataframe to csv
ndarray to csv

https://stackoverrun.com/ko/q/9610780

https://cnpnote.tistory.com/entry/PYTHON-%EC%98%88%EC%B8%A1-%EA%B2%B0%EA%B3%BC%EB%A5%BC-CSV%EB%A1%9C-%EC%A0%80%EC%9E%A5

https://stackoverflow.com/questions/6081008/dump-a-numpy-array-into-a-csv-file

pandas basic

https://iludaslab.tistory.com/45

https://hogni.tistory.com/7

# 201101

- 수업 개요

본격적으로 딥러닝 배울 것. 지금까지는 머신러닝 학습함.
인공 신경망 배울 것

- 수업 내용

## DC_chap8_1

4페이지

Perceptron
인공신경망
스스로 학습가능한 것에 가능성 높임

아무리 선을 그어도 하양과 검정을 구분할 수 없는 perceptron문제 발견(xor)
-> multi-layered 되면서 해결

본격적인 딥러닝은 2010부터 시작됐다해도 과언이아님

5페이지

물체를 보고 뭐냐인지를 맞추는 분류문제(클래스(범주)가 1000개인 분류문제라고 할 수 있겠지)

6페이지

y축: 에러율

xrce이런건 딥러닝 모델들이라고 보면됨

9페이지

각 레이어들에 노드가 있다

10페이지

레이어가 얼마나 많냐 적으냐에 따라 신경망의 종류가 나눠짐

입력층에서 바로 출력층으로 연결되는건 단층신경망

딥러닝: 심층신경망을 이용한 머신 러닝

11페이지

보통 예측값은 0~1사이의 값으로 표현함

에러가 발생한걸로 네트워크(weights라는 값을)를 업데이트함
노드와 노드를 연결하는 선들에 붙어있는 값 = weights(가중치)

신경망에서의 학습의 의미
입력값을 주면 쭉 거쳐서 아웃풋을 냄
에러가 줄어들 때까지 가중치를 업데이트하고 이를 반복함
weights값이 튜닝이되는거지.
학습하고 나면 구조와 weights값이 fix가 되겠지
예측을 원하는 값을 넣으면 예측값을 주겠지.

12페이지

딥러닝 패키지 이용하면 쉽게 문제를 해결할 수 있음

우리는 keras 주로 쓸 것

## DC_chap8_2

14페이지

사용자가 다수의 신호를 입력하면 이를 하나의 신호로 출력한다.

15페이지

생물학적 뉴런을 모방

신호(자극)
신호가 수집되어 자극이 일정치 이상 넘어가면 전달되는 -> 아웃풋

16페이지

perceptron 단순한 신경망이긴한데
복잡한 신경망의 기본이 되기 때문에
용어들 숙지할 필요있음

인풋값과 노드들이 연결되는 선에는 값이 있는데 이것이 가중치⭐

중간값 v를 네모 박스(파이 함수=활성함수⭐)에 집어넣으면 y를 도출할 수 있음

b(편향)

우리는 활성함수를 0또는 1이 나오는걸로 가정하고 할 것(학습용)
(원랜 0~1사이 어떤 값이 나옴)

17페이지

x에 붙은 T는 transposi(가로 세로를 바꾼 것)

알파벳이 진하게 나오면 이건 여러값이 모인 벡터임!

18페이지

'잘 조절하는' -> 러닝의 핵심이 되겠지. 모델에서 해줄 것

19페이지

앞에서 살펴본 용어들의 실제적인 의미를 살펴볼 것

가중치(weight value) ⭐
여기선 전류가 입력값들이 되겠지
입력값의 흐름을 조절하는 역할을 하겠지
왜? 원하는 y가 나오게 하려면 잘 조절해야 하기 때문

w1이 크면 x1(입력값)도 커질 것이고
w2이 작으면 x2도 작아질 것이고

저항의 역할: 흘러가는 전류의 양을 조절함으로써 원하는 전류의 양이 흘러가도록 함
저항을 통과하면 전류가 작아짐
저항이 크면 전류가 적게 흘러가고
저항이 약하면 전류를 많이 흘려보내기 때문에 좀더 많이 흘러감

20페이지

bias(편향)

(현실에서 잘 쓰이진 않으나 개념은 알아야지!)

세타값이 0이라고 보면

v=(뭉탱이) + b
b 절대값이 크면 뭉탱이도 커야되고
b를 낮춰주면 좀 쉽게 1이 될 수 있고 너무 크면 1이되기 어렵겠지

0(비활성화)
1(활성화)

21페이지

편향이 있는 이유
(입력값으로 부터 결과 y가 나오는데) 결과값 y가 특정 쪽으로 치우치게 나오도록 조절하는 것
실제 신경망에서 잘 쓰지는 않는다.

22페이지

활성화 함수

중간계산값(가중합) v를 0~1 사이로 변환하는 역할
여러 종류의 활성화 함수가 있겠지

## DC_chap8_3

24페이지

이렇게 다섯가지 입력값이 있을 때 손으로 계산해보기

25페이지

이젠 직접 코딩해보기

range(5) -> 0,1,2,3,4
i번째 행을 하나씩 갖고옴

26페이지

and 연산

이것을 perceptron으로 구현할 수 있을까?
(xor연산은 안됨)

and 입력값 이럴 때 이렇게 결과내는 perceptron을 만들 수 있나 보는 것

28페이지

존재하는데 여러가지 경우가 존재한대

29페이지

neural netword 이용해 분류문제에 적용 많이할 것

신경망을 어떻게 만들지 고민할 것

첫번째 예

feature가 5개이니(class label 빼고) input 노드의 개수는 5개겠지
output노드의 개수 = 클래스 수

인풋값은 보통 1보다 작은 값들
아웃풋값은 0~1사이의 값

❓
hidden layer의 개수를 몇개로 할거냐?
hidden layer 별로 노드의 개수는 몇개로 할거냐?
활성함수는 모든 레이어의 노드마다 붙어있는데 이건 어떻게 할건지
bias값은 어떻게 할건지

=> 이런 것들을 정하는게 신경망을 설계하는 것

두번째 파트

노드가 2개만 있어도 세로로보면 4가지 구분할 수 있지만 이 방법 쓰진 않는대

노드 4개 쓰고
1000 이면 (세로로 본것) 0클래스이고
0100 이면 1 클래스이고
이렇게 구분을 한대(one-hot coding)

30페이지

활성함수가 붙으면
계산되서 거쳐서 나갈 때는 값이 무조건 0~1사이라는 거지

가중치 -1~1 혹은 0~1 사이 값 줌

계속 곱셈 연산이 신경망에서 이루어지기 때문에 1보다 작은 값 선호
값이 무한히 커지는 것을 막을 수 있음

31페이지

xor 한쪽만 1이어야 1

32페이지

xor 안되는 문제 해결

layer가 여러개 있는 perceptron 사용하면 된다.

33페이지

키워드보고 이게 뭐다라고 설명할 수 있으면 이해 된거겠지

# 201104

## DC_chap9_1

3페이지

y 0~1
w -1~1 혹은 0~1
x 0~1 혹은 -1~1 로 변환하여 넣음
(곱셈연산이 많기 때문에 이렇게 1보다 작은 값 많이 사용)

4페이지

w값을 조정하는 것을 반복하여
y(예측값)과 정답 사이의 오차가 줄어듦
이게 뉴럴 네트워크의 학습 원리

-> 어떻게 조정하는가?(오늘의 학습 목표)

5페이지

편향(b)없을 때

6페이지

y = f(x)

7페이지

softmax

y로 가기전에 노드(동글뱅이)가 여러개면 소프트맥스쓰는게 좋음
(class가 3개면 이 노드도 3개래 저번시간에 설명한 것처럼)

8페이지

어떤 입력값있을 때 결과가 이렇게 나오면 얘는 class 1일 확률이 65.90프로 라고 해석할 수 있겠지

다른 값들도 사용해서 0~1값을 내는 특징이 있음

softmax와 sigmoid 모두
v가 어떤 값이 들어오더라도 0~1사이 결과를 내는 공통점이 있다.

10페이지

--실제 어떻게 학습하나--

delta rule

그림

ei = 에러(오차),차이

class가 2개인 경우

입력값중 큰게 있으면 결과에도 영향 크니까
오차에도 영향크겠지 -> 이 입력값에 연결된 w 많이 조정

11페이지

활성화 함수가 그냥 가중합 그대로 통과시키는 함수라 할 때

뒤의 w: 조정 이루어지기 전에 w(갱신전의 w)
앞의 w: 갱신 후 w

델타w = 에러 _ 입력값 _ 알파
(에러가 크면 클 수록, 입력값이 크면 클 수록 델타w는 커짐 -> 피피티 전 페이지의 내용과 통하는 얘기)

12페이지

v는 각 입력값에 가중치 곱해서 각각 더하면 됨

d가 정답

e는 에러

아래 식 ej\*xi 로 고치기

13페이지

w가 변동을 조금씩 하면 에러가 줄어드는 정도도 적겠지. 학습시간이 길어짐

15페이지(손으로 계산)
e는 에러
에러가 줄어드는지 확인해보기

## DC_chap9_2

위에서 배운 것 과 달리

활성함수가 어떤게 들어와도 처리할 수 있는 보편화된 델타룰을 배워보자
미분이 관여됨

17페이지

델타 제이! = 파이의 도함수(활성함수를 미분한 것)*가중합*에러

2번이 처음 배운 델타룰과의 큰 차이점

18페이지

그대로 통과하는 친구의 경우
(우리가 처음 배운 델타룰)

19페이지

함수가 시그모이드라면?
(수학수업아니니까 자세한 계산과정은 생략)

20페이지

파이(v)는 y이기 때문에
시그모이드에선 이렇게 간단하게 표현될 수 있음

21페이지

왜 미분해야 에러가 줄어들까?

경사가 작은쪽으로 한발한발 내딛으며 내려가겠지(그럼 목표지점인 평지에 다다를 수 있음)

22페이지

사람이 w, 옮겨가는게 w
미분을 하는 이유는 w를 증가시켜야하는지 감소시켜야하는지 알 수 있기 때문(그래프 왼쪽쯤에 있으면 w를 증가시켜야할거고 오른쪽쯤에 있으면 감소시켜야할것)

조금씩 내려갈지 성큼성큼 갈지를 알파가 결정함

폭이 크면 에러가 빠르게 줄어드나 정답부근에서 왓다갓다하거나 혹은 진동해서 에러값이 주나 싶더니 늘어나는 경우도 있음
폭이 작으면 w가 조금씩 변화하니까 에러가 조금씩 줄어 학습시간이 오래걸림. 대신 정답에 근접할 가능성이 커짐

## DC_chap9_3

지금까진 일반화된 델타 롤을 살펴봤음

28페이지

w는 어떻게 표현하나?

29페이지

2가지 방법이 있음
3\*2가 좋음(x1이 첫줄, x2가 두번째줄,... 잘맞음)

w12(인풋이 1이고 (동글뱅이)아웃풋이 2)

31페이지

wt(행과 열을 바꾸는) -> 곱해주려고 트랜스포즈함

y는 파이에 v를 넣은 결과

32페이지

파이썬 행렬 연산은 matmul 사용

33페이지

행렬 연산 많음
(아직 안배운 히든 레이어 까지 들어가면 연산 엄청 많음)
연산 gpu로 해결
행렬 연산을 병렬로 처리해 학습시간 줄이는
또는 분산병렬처리(어렵대)

딥러닝 돌리려면 컴터 스펙 좀 되어야해

34페이지

원핫코딩

클래스개수에 따라 아웃풋 노드 개수 맞추고
각 노드에서 나온 값을 모아 클래스를 식별

target 클래스

keras 쓰면 더 단순하게 할 수 있음

## DC_chap9_4

36페이지

품종 맞추는

총 5개의 컬럼중 하나가 class label
변수값은 4개 -> 인풋노드 4
클래스가 3개니 -> 아웃풋 노드 3

w는 -0.5 ~ 0.5 사이 값으로 랜덤하게
runif() 사용

1000번 w 업데이트

38페이지

둘 중에 뭘 전치해야하나
이거 잘 구현하면 된대

39페이지

import random

y가 d(정답)

SLP_SGD 맞게 구현하래

40페이지

에러가 줄었다가 늘었다가 하기도함

오른쪽은 w값

924번째까지가 에러가 제일 작네
이쯤에서 멈추면 좋앗겠지
그니까 오른쪽 w의 결과는 924에서 멈춘것보단 안좋은 w

41페이지

Test라 써있지만 사실 iris 데이터를 모두 넣어 테스트하는것이므로 트레이닝이라고 볼 수 있음

w에다가 x를 하나하나넣는거래<?>

argmax 줄 어느 클래스인지 담김

target 정답

w가 랜덤이니까 실행마다 값이 다르게 나올 수 있음
random_state를 주면 편리

42페이지

중요

w세줄
w를 만들어가는 과정

for문 돌리는 이유
한행씩 읽어서 w에 넣고 정답 나오면 w업데이트하고 이런식이니까

안의 for문 행 쭉 다도는거
바깥 for문 w를 1000번 업데이트니까 1000번

회색박스
안에 행렬 전치 어떻게 시킬지 알아봐야함

43페이지

## DC_chap9_5
