# 목차

[200901](#200901)

[200911](#200911)

[200915](#200915)

[200922](#200922)

[200929](#200929)

[201006](#201006)

# 200901

## 수업 개요

### 교과목 목표

- 딥러닝의 기본 개념
- 딥러닝을 현실 문제에 적용할 수 있는 방법론 학습
- 카페(Caffe), 텐서플로우(Tensorflow) 등 주요 딥러닝 프레임워크
- 클라우드 환경에서의 데이터 처리

### 기대되는 학습성과

- 파이썬의 딥러닝 관련 라이브러리 활용 가능
- 머신러닝의 개념 이해(딥러닝보다 넓은 차원의 개념)
- 클라우드 컴퓨팅의 종류와 동작 방식
- Keras(프레임워크)를 이용해 딥러닝 문제를 해결

1주차

## Deep Learning

인공지능: 기계 등이 인간과 같은 지능, 판단 할 수 있게 하는 -> 이것의 연장선상에 딥러닝이 있음

![image](https://user-images.githubusercontent.com/33214449/92207133-b28f7180-eec3-11ea-9a91-68d3b779d290.png)

출처: https://www.datacatchup.com/wp-content/uploads/2019/05/image.png

## Cloud

온프레미스
IaaS
PaaS
SaaS

![image](https://user-images.githubusercontent.com/33214449/92207542-5aa53a80-eec4-11ea-97d9-d8a2d433cffd.png)

## 실습 환경

PC - Anaconda 를 이용해 Python 사용할 것
Cloud - GoogleColab

# 200911

2주차

## 주의

문법 위주의 설명. 강의에서 코드실행은 하지 않으니 코드를 실행해볼것

파이썬은 인터프리터 언어(컴파일 과정이 없음. 라인바이라인 실행. 명령어를 치면 바로 결과를 확인할 수 있는)

텐서플로같은 잘 알려진 딥러닝 라이브러리를(API를) 파이썬이 지원함
딥러닝, 머신러닝할 때 데이터를 다루는 것이 중요한데 파이썬은 numpy같은 라이브러리를 제공하고 다루기가 용이

5페이지

제곱은 \*\*

7페이지

파이썬은 명시적인 변수 선언이 없다

초기화를해야 변수를 쓸 수 있음

변수의 값을 확인하는 방법

- 1. 명시적으로 print
- 2. 변수명만 입력해도 변수의 값이 출력됨

2번째 강의 ~

8페이지

따로 char 없음
bool형은 대소문자 지켜서 쓰기 (True, False)

12페이지

`{0}` 여기에 어떤 값이 출력되는데 뒤에서 보면 x가 넣어지는 것

13페이지

`{0}` `{1}` `{2}` 안에 숫자는 인덱스를 나타내는 것

14페이지

뒤로가면 리스트보다 편한 거 쓰지만 알아야되긴하니까 함

17페이지

range()
뒤는 +1임 기억
range(5,10) 5~9까지 만듬
range로 만든 요소값은 변경 불가

18페이지

range 형을 list로 바꾸면 요소를 수정 가능

시작 숫자 생략하면 0부터 시작되는 수열
range(10) : 0~9

19페이지

tuple -> 잘 안씀 그냥 넘ㅇ어가~

a = (1) 이렇게 쓰면 int로 인식

3번째 강의~

22페이지

같은 깊이로 들여쓰기 할 것!

23페이지

and or

24페이지

enumerate 열거형
순서는 i, 실제 값이 들어오는건 n

25페이지

numpy 넘파이를이용한 배열
파이썬 라이브러리-> 모듈이라고 부름
리스트도 있지만... 넘파이는 배열을 쉽게 다룰 수 있게 해줌
리스트보다 처리 속도가 50배정도 빠르다
n차원의 배열을 선언할 수 있다.(넘파이에서 배열객체를 ndarray라고 함)

26페이지

넘파이에서 1차원 배열은 vector라고함

28페이지

numpy.arange

29페이지

벡터연산(리스트와 차이)
배열과 배열의 덧셈이 됨(c언어라생각하면 for문 돌려서 해야됐을것)
연산하려면 차원이 같아야됨

30페이지

2차원->array

array 의 크기
2행 3열 의미
dtype 데이터 타입!

4번째 강의~

31페이지

2행 10열의 배열이 생성됨

32페이지

rand 0에서 1사이 랜덤한 거 나옴

(seed 같으면 랜덤하긴해도 내가하든 남이하든 같은 랜덤값
seed 다르면 매번 다른 결과)

33페이지

reshape 원소의 총 개수는 같아야 사용 가능
벡터를 차원으로 바꿀 수도 있음, 2차원도 옆으로 늘려 벡터로 만들 수도 있고

36페이지

배열값 각각에 대해서 수학 연산 할 수 있음

37페이지

행렬곱셈 의 의미(딥러닝에서 많이 쓴대)
v.dot(w)

w.dot(v) 와 결과 다름

38페이지
잘라내 여러개 추출할 수 있다

[:5] 처음부터 5인덱스 바로 전까지 자름
[2:5] 인덱스 2 부터 인덱스 5전까지. 즉 인덱스 2,3,4

[n:] n부터 끝까지 다

39페이지

[:,1] 행은 처음부터끝까지, 열은 1행만

41페이지
함수에 대해서 알고싶을 때

43페이지

파이썬에서는 리턴값을 여러개 줄 수 있음

(파이썬은 블록단위로 다른문장 먼저 실행하면 그 데이터 갖다쓰는 코드 그다음에 실행해도 실행되네)

44페이지
배열의 값을 파일에 저장해놓을 수 있음(중요한 결과값이라면 이런 과정 필요!)

45페이지
많이쓰진 않음

# 200915

3주차

chap03_1,2,3 부분 피피티 다시 정독할 것

## 수업 개요

- AI scopes
- Machine learning
- Machine learning areas
- Development process of learning model
- Sciket-learn

## DC_chap03_1_compact

3페이지
머신러닝은 독립적인 분야라기보다는 많은 것과 관련되어있다(인공지능에 속하고, 패턴 인식, 통계학, 시각화 등과 관련 있음)

4페이지
머신러닝 이나 데이터마이닝 겹치는 부분 있어. 대량의 데이터가 관여된다.
데이터마이닝: 정보를 뽑아내는
머신러닝: 데이터를 토대로 예측하는

5페이지
인공지능: 컴퓨터가 사람처럼 행동하게끔 할 수 있게하는 기술
머신러닝: 통계적인 방법과 데이터를 활용해 문제를 더 잘 해결하게끔하는 인공지능 기술
딥러닝: 뉴럴 네트워크

6페이지
머신러닝이 뭘까? 머신이 기계일까 학습한다는 것은 무엇일까?
구체적으로 뭘 한다는 것일까?

7페이지

머신러닝 (실제적인 의미): 과거의 경험을 미래의 결정(예측)에 활용하는 소프트웨어를 디자인하고 연구하는 분야

=>과거를 공부해 미래를 예측하는 기술
과거 데이터로부터 숨겨진 규칙을 찾아내 일반화-> 이를 미래 예측에 활용

과거의 경험 자체를 잘 이해하는 것 유용한 정보를 뽑아내려고 하는 것=> 데이터 마이닝
여기서 규칙을 찾아 미래 예측에 활용하려 하는 것은 머신러닝

전통적 SW
규칙을 인간이 알아내어 알고리즘 형태로 SW 안에 구현한 것(이게 규칙이겠지~)
누가 알고리즘을 잘 만드느냐가 SW엔지니어의 능력이었음
(알고리즘은 규칙을 찾아가는 과정을 다 서술한 것)

머신러닝
규칙을 알아내는 방법은 인간이 제시(방법론만을 제시)
머신이 규칙을 찾는다. (전통적 SW 와의 차이)
머신이 과거데이터로부터 규칙을 알아내는 과정이 '학습'(머신입장에선 학습, 인간입장에선 머신을 '훈련'시키는 것)

인공지능 > 머신러닝 > 딥러닝 (포함관계)

머신러닝: 과거의 축적된 데이터를 '학습'하여 미래를 예측하는 기술

8페이지

머신 러닝은 기본적으로 데이터가 있어야한다.

예측모델 -> 규칙을 의미 (어떨 때 주가가 이렇더라)
이제 데이터가 있고 내일 주가를 모르면 그 데이터를 모델에 넣어 주가 예측할 수 있는 것

9페이지

머신 러닝에서 '머신' -> SW, 프로그램

10페이지

머신러닝이 사용하는 학습 자료는? 데이터
엑셀 형태의 데이터. sns에서 오가는 데이터들, 이미지, 음성파일 등

11페이지

'러닝'은 무엇인가?

설명변수:아까 본 주식에 영향을 미치는 요인들(여러개)
반응변수:요인들에 의해 결정되는 주가(하나)

잘 정돈된 데이터인 데이터셋(설명변수, 반응변수)를
학습방법에 집어넣으면... 러닝이 됨(머신입장)
학습의 아웃풋은 예측 모델이라함

12페이지
러닝의 사례들

13페이지
이런 학습 알고리즘을 잘 사용할 줄 알면됨

15페이지
관건은 얼마나 정확한 모델을 만드느냐가 관건

## DC_chap03_2_compact

17페이지

우리수업에선 지도학습 주로 학습(비지도학습은 조금, 강화학습은 다루지 않음)

- 지도학습 (가이드하는 학습방법)
  문제, 답을 같이 줘서(설명변수, 반응변수를 같이 주고) 학습시키는 것이 지도학습

  - 회귀(답의 형태가 수치형. 값이 있고 크기 비교가 가능한)
  - 분류(답이 범주형.)->수업에서 제일 많이 다룰 것

정답의 형태에 따라 회귀, 분류로 나눠짐
맞추고자하는 답의 형태가 수치형이면 회귀
(분류문제 가장 많이 다룸)

- 비지도학습
  문제만 주고 답은 안줌

18페이지

세모를 모델에 넣으면 -인지 +인지 알려주는 (분류의 예)

처음엔 그룹이 뭔지도 모름
그룹이 어떻게 구성되는지 찾아봐라(군집화)

위 둘의 차이는
분류는 그룹 정보가 이미 주어진다.
군집화는 그룹 정보 없이 스스로 그룹 정보를 만들어내야함

19페이지

오존이 120 일때 기온은 얼마일까? 예측 가능
예측해야될 대상이 클래스나 범주가 아니라 숫자라면
regression

20페이지
처음에는 비실비실한데 나중에는 잘 치게 됨

## DC_chap03_3_compact

요 영상 중요하대

22페이지

개발자 입장에서 어떻게 모델을 개발하는지 과정 도식화한 것

학습에 사용할 training data
학습에 사용하지 않는 test data 로 나눔

만든 모델의 성능을 평가하는 것이 굉장히 중요
(평가를 어떻게 하지? 어차피 미래를 예측하는 건데?)

test data가 미래 데이터로 보고
학습에 안쓴 test data를 미래 데이터로 보고 이걸 가지고 예측해 예측 결과를 도출.
그리고 test data는 이미 결과를(Y) 가지고 있으니까 예측한거랑 이거랑 비교해서 모델을 평가

validatoin data 는 현재 이루어지고 있는 학습 과정이 잘 가고 있는지를 평가하기 위한 데이터이다.(부족한 부분 보충) 어떤 모델은 이게 있고 어떤 모델은 없는 알고리즘도 있음

---

머신러닝의 아웃풋은 '학습 모델'

22페이지 표 자주 나올 것

test data(일부 남겨놓은)를 미래 데이터로 보고
그 학습과 학습시킨 모델과 비교

비교해 많이 일치할 수록 모델이 정확도가 높다 이렇게 판단할 수 있음

---

24페이지

각각 모델 의 결과와 이미 있는 결과(Y)를 이용해 accuracy 도출 가능

왜?
training data를 통해 학습했기 때문에 training accuracy 정확도가 높음

## DC_chap03_4_compact

파이썬에서 머신러닝을 위해 사용되는 두가지 라이브러리 소개할 것

25페이지

1. sciket-learn (라이브러리1)

여기 있는 함수 많이 배울 것

26페이지

2. pandas (라이브러리2)

학습에 쓸 데이터가 보통 파일에 저장되어있는데 그걸 불러와서
데이터 프레임(넘파이에 있는 것 처럼 2차원 배열같은)에 저장할 수 있음
그리고 그 데이터프레임을 가공 가능(어디부터 어디까지 잘라서 쓰고 등등)

27페이지

꽃받침의 길이와 너비, 꽃잎의 길이와 너비(x) 주고 이게 품종(y, 결과)이 뭘까? 분류할 수 있을것(이 학습데이터를 바탕으로)

28페이지

iris 가 데이터프레임을 담고있게됨

with display.max... 생략된 데이터 없이 행, 컬럼 다 보일 수 있게함

head() 데이터를 앞부터 몇개만 보고싶을 때
인수로 숫자를 주면 몇개도 설정가능

tail()은 그 반대

iris.shape 행과 열만 알고싶을 경우

columns 컬럼의 이름을 보고싶은경우(컬럼은 실데이터는 아님)

columns[:4] 앞에서 시작해 4번째까지(0,1,2,3)

iris['컬럼이름'] 해당하는 컬럼 데이터만 가져옴
iris[['컬럼이름', '컬럼이름']]
이렇게 잘라내고 또다른 변수에 저장해 데이터프레임처럼 쓸 수 있음

iloc도 기준이 행은 인덱스고 열은 0부터시작하는 값인듯
iloc 인덱스를 이용해 자르는 방법
iloc[90,4] 인덱스 90에 해당하는 행과 4에 해당하는 열 -> 열도 0부터시작하니 실제론 5번째 열에 있는 데이터가 나올 것

iloc[10:50, 0:4] 10~50 행, 0~4열에 해당하는 데이터 가져오는
iloc[10:50, :] 10-50 행, 열은 모두 라는 의미

조건을 주고 자르는 경우
논리식은 데이터마다 t, f 판별한 정보 가지고 있음
iris[setosa] 품종이 setosa 인 것만 보여줄 것
& -> and의미 두 조건을 만족하는 것만 골라오는 것

30페이지

어떤 모듈 설치되어있는지 확인 가능한 명령어

# 200922

## 수업 개요

1. Simple linear regression 단순 선형 회귀
2. Multiple linear regression 다중 선형 회귀
3. Logistic regression

회귀문제 이면서 분류도 풀 수 있음 오늘 다룰 것

## 수업 내용

### DC_chao04_1_compact

1. Simple linear regression

4페이지

독립, 종속 변수의 두 관계가 선형관계인지 파악하고(하나 증가하면 다른 하나도 증가하거나 하나 감소하면 다른 하나도 감소하거나) 이를 예측에 활용하는

모델 = (구체적으로 말하면)학습 모델

머신이 W,b 같은 상수를 알아내게 하는게 목표임

6페이지

산점도

오른쪽 두개는 선형관계가 아닌 경우임

오른쪽위는 이차식이 될 것

왼쪽것에 단순선형회귀를 적용할 수 있다.

7페이지

(a) 가 더 좋아보이는데
이걸 객관적으로 평가할 수 있는 척도가 필요함

8페이지

오차들의 합계가 가장 적어야함

예측값-실제값이 마이너스인 경우도 있고 플러스인경우도 있음
그래서 각각을 제곱해서 더해줌.

12페이지

regression 하려면 넘파이 배열로 담아줘야함.
그리고 reshape으로 2차원 배열이 되도록해줘야해(여기서는)

13페이지
test_size=0.2
test data를 20프로로 하겠다는것(그럼 training data는 80프로가 되겠지)

random_state 랜덤 시드값 (실행시마다 랜덤으로 정하는 것 고정시키려고)여기선 train test 나누는 것을 랜덤으로 햇을때 그걸 이후에도 사용하기 위해서

14페이지

모델만들 때 방법 지정

fit=learning 학습하여 W,b얻을 수 있음

predict로 예측
pred_y랑 test_y랑 비교해서 정확한지 보면되겠지

15페이지

값 하나로 예측하고 싶을 때(곽갈호 2개인 것에 유의-predict가 2차원 배열을 받아들이기 때문에)

16페이지

실제는 아래 코드처럼 써야함

W,b 출력할 수 있음(학습이 끝난 모델안에 들어있는 것)

17페이지

모델 평가 1

mean squared error
실제값-정답값 의 제곱을 더해 평균낸 것(오차의 제곱의 합 평균)
이 값이 작을 수록 정확한 모델

0이면 예측이 정확하다는 것인데 이는 이상적인 값

근데 이 오차가 얼마나 작은것인지를 추측하기가 힘듦

18페이지

모델 평가 2

r2 score
1에 가까울 수록 좋은 모델인 걸 알 수 있기 때문에 모델 평가 1보다 보기 쉬움

19페이지

scatter 산점도 그리는 것
plot 라인 그리는 것

### DC_chao04_2_compact

2. Multiple linear regression
   중 선형 회귀
   다중 선형 회귀

20페이지

독립변수가 2개 이상인 경우(단일 선형 회귀와의 차이점)

intercept 편차

22페이지

c income 연봉을 예측하고싶음(선형)

교육년수, 여성비율, 직업에 대한 평판 쓸 것

26페이지

단순 선형 회귀와 코드 방식은 비슷

27페이지

독립변수가 3개라 coefficient계수도 3개가 나옴

28페이지
각괄호 2개 해도 되고
이렇게 reshape 써도 되고

### DC_chao04_3_compact

3. Logisic regression

분류 문제를 회귀 방법으로 풀려고 하는 것

30페이지

이것도 어차피 회귀라 품종도 숫자로 나타내야함

33페이지

전체 정답중에 정답을 맞춘 개수

분류가 logistic regression 보다 성능 좋지만 배우는 건 필요하니까!

# 200929

5주차

## DC_chap05_1_compact

1. remind: clustering, classification

3페이지

clustering(군집화)
비슷한 데이터들끼리 묶는 작업
(알아서 묶음)비지도적 학습
거리가 가까운 것들끼리 묶음-> 거리계산이 중요

4페이지

classification 분류
이미 범주를 알고 있음
남자 / 여자 나눌 때 어떤 정보가 남자인지 여자인지 구별
예측, 진료에 많이 쓰임
이 수업에서 많이 배울 것
지도적 학습(이미 범주데이터-정답이 주어지기 때문에)

6페이지

이렇게 그룹을 만들어 해석.
속도는 느리고, 무게는 무겁고...~~~ 아마 화물차일것

그룹지어짐>특성 존재

7페이지

환자와 정상인
아래 데이터를 보고 어떤 범주(환자or정상)에 속하는지 구하는

8페이지
분류는 이미지를 가지고도 할 수 있다.

사진속 장소 이름 뭔지 모르겠을 때 > 비슷한거 찾음

9페이지

분류가 두개일 때 -> binary

multiple
알파벳은 스물 몇개겠지(클래스가)

binary vs multiple 뭐가 쉬울까?
binary가 쉽겠지. 찍어도 50프로니
모델의 정확도가 비교적 높다는 뜻

## DC_chap05_2_compact

2. k-means clustering

11페이지

서로 다른 주파수대역에서 음파를 측정
금이가고 안간 타일을 구분하기 위해

군집화해서 금간것끼리 금안간것끼리 묶여야 사용 가능

12페이지

로그값을 취해 값을 좀 줄여줌(logarithms)

k=>클러스터의 개수
금이간 타일 정상 타일 예는 k=2이겠지

14페이지
가상의 점 k개 찍기
-> 각 클러스터의 중심점이 될것
이 점들과 나머지 원래 데이터들의 각각 거리 측정
(각각의 점이 가상의 점들 중 뭐랑 가까운지 계산하고 그룹화)
더 가까운 점을 포함시켜 중심점 계산(x좌표 다 더하고-가상 점 포함- 점 개수만큼 나눔.)

![image](https://user-images.githubusercontent.com/33214449/95008868-68cbaf80-0658-11eb-80a2-c8945025af8c.png)

15페이지

14페이지 반복

22페이지
labels
각 데이터의 클러스터 뭔지

붙여서 잘 보여주려고 한것
hstack 수평으로 쌓기

reshape(-1,1) 행은 너가 알아서 맞춰 라는 뜻
21페이지에 있는 데이터랑 붙이려면 reshape 해줘야해(세로로 세우는 작업)

cluster_centers 중심점
첫번째께 0번 클러스터, 두번째께 1번 클러스터

[0,0]은 어떤 클러스터일까 이렇게 추측해보는 것 (predict)

## DC_chap05_3_compact

3. KNN classifier

25페이지

별 데이터는 동그라미인지 세모인지 모른다고 할 때

knn
모르는 데이터에 가까운애들을 줄임(7-nn)
그중 많은 클래스를따른다.(여기선 동그라미)

26페이지

클래스수가 동수일때는 어떻게하나?
K를 몇으로 해야되나 이슈가 발생

27페이지

거리계산은 k-means에서 봤던 식과 같음

28페이지

루트 n보다 작게 k를 잡아라

29페이지

색깔있는 숫자가 정답

아래 색깔 그려진건 예측값

k숫자가 커질 수록 예측값 정확도가 점점 떨어짐을 볼 수 있음

k 1,3,5 다 해보고 제일 정확한걸 고름
하이퍼파라미터: 모델을 만들 때 모델의 정확도(성능)를 결정하는 몇가지의 변수들을 의미(knn에서는 하이퍼 파라미터가 k 하나겠지)

30페이지

데이터 분포가 어떻든지 분석 가능(통계적 가정 불필요)

데이터 커질 수록
새로운 데이터를 데이터들과 거리를 계산해야되서
데이터를 메모리에 다갖고있어야됨

계산도 많이해야되니까 처리시간 증가

32페이지

k값을 3으로 줌

fit함수 -> 학습하는 것

classfication 분류에서 모델 성능 평가시 많이 쓰는 것 accuracy
(전체 테스트 데이터 갯수중에 정답맞힌 갯수)

34페이지

ex예로 거리를 계산해보면
실제로 차이가 많이나는 건 시력인데(1.0 과 0.1)
거리 값에 영향을 크게 미치는 건 키 값임을 알 수 있음
둘의 스케일이 다름

키도 0~1로 시력도 0~1로 동일한 영향력을 갖도록 스케일링을 해줘야함

kmeans knn 하려면 스케일링 해야함

## DC_chap05_4_compact

4. perfomance metric

37페이지

성능 평가!

binary classification의 경우 이런 성능평가 척도 가지고 있다.(why 모델이 어디 적용되느냐에따라 다양한 것이 사용됨)

38페이지

T : 잘 맞춘것

FP,FN은 오류
FN이 더 심각하지(코로나라고 생각하면)

accuracy는 경우중에 정답인 것만

39페이지

민감도
ex) 양성인 사람중에 양성이라고 예측한 비율

특이도
ex) 음성인 사람중에 음성이라고 예측한 비율

의료환경에서는 무엇이 중요할까? 민감도가 중요할 것.(환자인데 음성이라고 진단한 경우가 높으면 큰일이니)

40페이지

정밀도

양성이라고 예측한 사람들 중에 진짜 양성인 사람

41페이지

f1 score
민감도와 특이도의 불균형 측정

민감도가 100퍼센트인데(1) 특이도가 0이면 f1 score는 0

불균형한 경우 척도값이 낮게 나오는게 f1 score

42페이지
class가 3개이면 성능 측정 어떻게 하나?
(multiple class model)

클래스별로 민감도 특이도를 계산할 수 있으나 잘 쓰지 않음

43페이지

classification에서 쓰는 척도들

모델을 만드는 것도 중요하지만 성능을 측정하는 것도 중요

45페이지
인자 줄 때 정답이 앞에 예측이 뒤에 와야됨!

46페이지
3x3행렬보면...
test_y가 정답임

정답은 0 인데 예측도 0으로한건 2개라는 뜻
대각선이 제대로 맞춘 것들을 나타냄

## DC_chap05_5_compact

5. k-fold cross validation

validation이니까 평가해서 알아보는 것임

이 결과를 믿어야할까?라는 것
training , test 데이터를 어떻게 나누느냐에 따라 정확도가 엄청 달라질 수도 있음

-> 해결하려면
나누는 걸 여러번 해서 평균을 할 수도 있음
아니면
k-fold cross validation사용

50페이지

k=4면 전체를 4등분하는 것

ex1에서 진한걸 test, 나머지 training
ex2도
ex3도
ex4도

각각의 accuracy를 평균하고
이걸 그 모델의 accuracy로 보자는 것

k=10이면
10번 나누겠지
10번 모델을 만들거고

51페이지

랜덤하게 나누니까 random_state 줘야함(이후에도 같은 결과 얻으려면)
shuffle 데이터를 마구 섞고 등분할거냐 물어보는 것

knn사용한 것

accuracy 저장할 크기 5인 배열 선언

53페이지

np.mean 평균

54페이지

좀더 단순한 방법

fold쓰지 않고 cross \_val_score 사용

단지 accuracy만 구하기 때문에 사이에 코드를 넣으려면 전 페이지처럼 자세하게 하는게 좋을 수도

55페이지

k-fold
원하는 모델을 도출하지는 않음(모델 여러개 나오잖아)
정확도를 추정하는 용도

knn쓴다했을 때
k정해야함. 여러번해서 좋은거 써야함
이때 k-fold 써서 k가 몇일때 정확도 몇이고 이런걸 구하는 것(하이퍼 파라미터 값 확정에 이용됨)

하이퍼 파라미터 튜닝 아직 안배움

feature selection
컬럼 중 모델에 도움이되는것 골라내는 과정
->에도 k-fold 쓴다.

오늘 중요한 내용들 많이 배웠대
다양한 데이터셋으로 연습할 것

# 201006

6주차

classification(분류) 방법 중 하나인 의사결정나무(decision tree) 학습할 것

## DC_chap06_1_compact

3페이지

분류에서 학습함이란,
클래스를 나누는 경계를 얼마나 잘 찾느냐(직선, 곡선 얘기)
3차원이 되면 면이 될 수도 있기 때문에 hyper plane이라고도 함.(클래스와 클래스의 경계)

4페이지

분류를 할 수 있는 많은 방법이 있음

svm
decision tree
random forest
주로 배울 것

xgboost 요즘 많이 쓰는. 수업에선 소개만 할 것

머신러닝처럼 노가다도 이런 노가다가 없다 그렇게 느끼게 될 것임

## 1.Decision Tree

5페이지

x1, x2값을 주고 색깔을 예측하는 결정 트리
sibsp 가족수

9페이지

decision tree 가 경계를 찾는 과정 배울 것

step1
일단 먼저 특정 두 클래스를 구분하는 선을 찾음

11페이지

전 페이지에서 보면 일단 split1 기준

(차지하는 수 / 전체 경우의 수)

celebrities(유명인사, 탑급배우) 나누는건 앞페이지에서 처음에 나눈 split1 선 기준으로 생각하면 됨(y축)

budget(예산)

12페이지

어떤 속성부터 선택할 것인가가 문제가 되는데...
고혈압 vs 정상 일때 두 클래스의 겹쳐지는 부분(교집합)이 제일 작은 것을 루투노드로 사용한다.(여기선 몸무게겠지)

13페이지

split을 언제 중단할 것인가(몇개까지 나누느냐)
경계선을 많이 나누면 예측은 정확해지겠지만, overfitting 발생(과적합) test데이터로 학습을 하면 예측이 떨어질 수도 있음. 적당할 때 트리 생성을 중단할 수 있어야함(과적합은 다음 시간에 배울 것)

14페이지

명목속성(범주형 자료)
속성(컬럼)

단점
훈련 데이터가 조금만 바껴도 트리가 크게 달라질 수 있음

대각선은 만들 수 없대 이게 단점!

## DC_chap06_2_compact

19페이지

category 클래스 정보
drinks 알코올

간 질환 있는지 검사하는 것이 목적

20페이지

df_X 코드부분 -> category가 아닌 것들만

22페이지

decisiontree 만들 때 랜덤하게 선택하는게 들어가기 때문에 random_state 값 줘야함(모델 정의할 때. 지정하지 않은 값은 디폴트값이 들어감)

train accuracy 1.0나왔는데 이건 100퍼 라는 뜻

confusion_matrix
23, 14가 에러고 나머지 대각선은 뭐라는데 모르겠음

23페이지

모델 정의시 인자 더 줄수도 있음
트리 깊이를 4로 제한.(자식이 생길 때마다 깊이가 1씩 늘어남)

트리깊이 적용했더니
test accuracy는 성능이 더 좋아졌음.

15,17 -> 32개의 오류 발생.(22페이지보다 좋아졌음)

-> 매개변수를 잘 조절하면 모델의 성능이 좋아질 수 있다.(다른 매개변수도 조정해 최상의 결과 내는 게 목표)

26페이지

하이퍼 파라미터
:모델 성능에 영향을 미치는 매개변수

min_samples_split
0~1 사용해 퍼센트로 줄 수도 있음
가지 분리시 각각 분배될 수 있는 최소 샘플수(10개를 두가지로 분리시 분리되고 나서 있을 수 있는 최소 샘플수)

27페이지

min_samples_leaf
하나의 노드가 가지고 있어야할 최소 샘플 수

max_features
컬럼을 모두 쓰진 않는다고 했지. 컬럼중 몇개로 제한할 것이냐

class_weight
클래스의 중요도
환자가 환자로 판명되는게 (반대보다) 더 중요하니까 (그런말임) 안그러면 큰일나자녀

⭐ 모델 만들 때 다양한 매개변수 줄 수 있음

중요한 것

- 어떤 모델을 쓸 것이냐
- 방법론이 결정됐을 때, 매개변수를 어떤 걸 지정해서 모델을 만들 것이냐

여러가지를 시도해봐야 어느방법, 어떤 방식이 좋은지 알 수 있음.

## DC_chap06_3_compact

## 3.Random Forest

29페이지

결정 트리를 응용한 개념

트리를 하나가 아니고 여러 트리를 만들어보자는 것

그럼 예측은 어떻게 하느냐
정답을 모르는 값을 트리1에 넣어보고
트리2에도 넣어보고
트리3에도 넣어보는
결과중 가장 많은(다수결)결과로 결정해서 예측하는 것

트리를 만들 때 랜덤하게 만들기 때문에 random forest

bagging
모델을 여러개(n개)를 만들어서 각각의 모델의 결과들을 취합해서 결과를 내는.

random forest는 bagging을 구체적으로 구현한 한 방법이다 라고 볼 수 있음

30페이지

bagging
데이터 인스턴스도 샘플링하고
컬럼도 샘플링한대

33페이지

n_estimators 트리의 개수 몇개로 할 건지

34페이지

트리 개수 올리니 성능 더 좋아졌음

매개변수의 값을 바꿔가면서 모델 성능을 향상시키는 방법을 하이퍼파라미터 튜닝, 모델 튜닝이라고 함.

35페이지

중요한 파라미터들을 적용하는 것이 필요
(파라미터 많아지면 튜닝 시간 길어지니)

## DC_chap06_4_compact

## 4.Support Vector Machine

37페이지

두 아이디어가 사용 1)경계선을 찾을 때 (모든 점의 정보를 이용하지 않고 경계면에 있는 몇개의 점을 이용해서 찾는다)클래스와 클래스 사이에 몇개의 점을 사용해 경계를 찾는 것. 그 몇개의 점을 support vector라고 함
-> 클래스 주어졌을 때 이 서포트 벡터를 어떻게 찾아내느냐가 관건

2. 2차원을 3차원으로 변형하게 되면 더 쉽게 나눌 수도 있음. 차원을 하나 높여 경계(면)을 찾아보자. (차원을 하나 높이는 방법이 kernel이라고 함)

38페이지 이론적 내용이라 스킵

39페이지

svm.SVC 분류(classification)에 많이 쓰임

40페이지

libsvm을 파이썬으로 재구현한 것
학습시간이 데이터셋의 샘플 수의 제곱수준으로 학습시간이 길다. (인스턴스가 많아지면 학습시간이 지수적으로 증가. 특정 개수 만개 넘어가면 실용적이지 않대 오래걸려서. 교수님은 만개정돈 괜찮대)

너무 오래걸리면 linearSVC이런거 고려해봐라는 지침

43페이지

매개변수
kernel 데이터셋의 차원을 높이는

모델 성능 떨어졌네

44페이지

c, kernel 주목!

C:
과적합이 일어나지 않도록 조절하는데 쓰이는 매개변수

kernel:
데이터셋의 차원 변형하는

degree는 poly 쓸 때 의미가 있음
다항식의 항의수?..

gamma
커널이 rbf, poly, sigmoid 일 때 의미가 있음
커널의 coefficient값을 정해주는

45페이지

여기만 봐서는 뭐가 좋은지 잘 모를 수도 있음
accuracy 확인 필요

1보단 2가 나은듯
3은 파란부분 잘 분류됐고 괜찮은듯
4는 이런식
1,2 보다는 3,4가 좋아보이는데 정확한건 accuracy 확인 필요 -> 실습통해 확인하기

46페이지

오랫동안 사랑받은 모델링

모델이 왜 이런식으로 결과를 내는지 해석이 어렵다.

## DC_chap06_5_compact

## 5.xgboost

48페이지

앙상블(여러개 모델을 만들어서 이를 통해 단일한 결과를 내도록하는... 예측 성능을 높이는 방법론)
그 중에 bagging, boosting 이 있음

bagging
모델을 여러개 만들어서 투표해서 결과를 내는.

boosting
예측 잘 안되는 그룹을 가지고 잘 될 수 있도록..
잘 안되는거에 중점을 둬서 이걸 예측을 잘해내면 점수를 더 주는
여전히 안되면 그걸가지고 또 모델을 만들고
... 그러면 모델이 업그레이드 된다
여긴 투표라는게 없음

49페이지

예측력이 평균적으로 최강이래 xgboost가!
복잡하긴 함
사이킷런 안에는 포함되어있지 않은 상황

50페이지

혼자 공부하려면 이런식으로 설치해서 써봐

## 6번 과제

Q1에서

scaling 작업을 해야 kfold를 할 수 있는 걸 알게됐음. scaling 복습 필요
